{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e42ec2-c358-4612-9595-5778e9ae8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Dict, List, Tuple\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from uuid import uuid4\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cec05f-69d4-4619-b400-b48665bdf063",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f5367a-313a-4f07-9306-f717d8c470cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf232086-d2f1-446d-bf22-8e46d9d9484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMDCDataset(InMemoryDataset):\n",
    "    \"\"\"Dataset class for TMDC crystal structures with defects\"\"\"\n",
    "    \n",
    "    def __init__(self, root, structures_dir, targets_csv, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root: Root directory where processed data will be stored\n",
    "            structures_dir: Directory containing JSON structure files\n",
    "            targets_csv: CSV file with structure IDs and band gap values\n",
    "            transform: Optional transforms to apply\n",
    "        \"\"\"\n",
    "        self.structures_dir = Path(structures_dir)\n",
    "        self.targets_df = pd.read_csv(targets_csv)\n",
    "        self.target_dict = dict(zip(self.targets_df['_id'], self.targets_df['band_gap']))\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"Return list of raw file names\"\"\"\n",
    "        return list(self.targets_df['_id'].astype(str) + '.json')\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"Return list of processed file names\"\"\"\n",
    "        return [f'data_{i}.pt' for i in range(len(self.raw_file_names))]\n",
    "    \n",
    "    def download(self):\n",
    "        \"\"\"Not needed as we have local files\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Process raw data into PyTorch Geometric format\"\"\"\n",
    "        print(\"Processing crystal structures...\")\n",
    "        \n",
    "        # Parameters for graph construction\n",
    "        cutoff = 5.0  # Ångström cutoff for bonds\n",
    "        max_neighbors = 20\n",
    "        gaussian_centers = 20\n",
    "        \n",
    "        # Periodic boundary handling for 2D materials (no periodicity in z-direction)\n",
    "        pbc = [True, True, False]\n",
    "        \n",
    "        for idx, (struct_id, bg) in enumerate(self.target_dict.items()):\n",
    "            # Load structure from JSON\n",
    "            json_path = self.structures_dir / f\"{struct_id}.json\"\n",
    "            \n",
    "            if not json_path.exists():\n",
    "                print(f\"Warning: {json_path} not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            with open(json_path, 'r') as f:\n",
    "                struct_dict = json.load(f)\n",
    "            \n",
    "            # Convert to pymatgen structure\n",
    "            structure = Structure.from_dict(struct_dict)\n",
    "            \n",
    "            # Get atomic numbers and positions\n",
    "            atomic_numbers = []\n",
    "            positions = []\n",
    "            \n",
    "            for site in structure:\n",
    "                atomic_numbers.append(site.specie.Z)\n",
    "                positions.append(site.coords)\n",
    "            \n",
    "            atomic_numbers = torch.tensor(atomic_numbers, dtype=torch.long)\n",
    "            positions = torch.tensor(np.array(positions), dtype=torch.float)\n",
    "            \n",
    "            # Build graph edges with periodic boundary conditions\n",
    "            edge_index, edge_vectors, edge_distances = self.build_edges(\n",
    "                positions, structure.lattice.matrix, cutoff, pbc\n",
    "            )\n",
    "            \n",
    "            # Build angle edges (for line graph)\n",
    "            angle_index, angle_values = self.build_angles(\n",
    "                edge_index, edge_vectors, edge_distances\n",
    "            )\n",
    "            \n",
    "            # Create node features (one-hot encoding of atomic numbers)\n",
    "            # Mo=42, W=74, S=16, Se=34\n",
    "            node_features = self.encode_atoms(atomic_numbers)\n",
    "            \n",
    "            # Create edge features (Gaussian basis)\n",
    "            edge_features = self.gaussian_basis(edge_distances, gaussian_centers)\n",
    "            \n",
    "            # Create angle features\n",
    "            angle_features = self.spherical_bessel_basis(angle_values)\n",
    "            \n",
    "            # Create data object\n",
    "            data = Data(\n",
    "                x=node_features,\n",
    "                pos=positions,\n",
    "                edge_index=edge_index,\n",
    "                edge_attr=edge_features,\n",
    "                edge_dist=edge_distances,\n",
    "                angle_index=angle_index,\n",
    "                angle_attr=angle_features,\n",
    "                y=torch.tensor([bg], dtype=torch.float),\n",
    "                structure_id=struct_id,\n",
    "                atomic_numbers=atomic_numbers\n",
    "            )\n",
    "            \n",
    "            # Save processed data\n",
    "            torch.save(data, self.processed_paths[idx])\n",
    "            \n",
    "            if idx % 100 == 0:\n",
    "                print(f\"Processed {idx+1}/{len(self.target_dict)} structures\")\n",
    "    \n",
    "    def build_edges(self, positions, lattice_matrix, cutoff, pbc):\n",
    "        \"\"\"Build edges with periodic boundary conditions\"\"\"\n",
    "        n_atoms = positions.shape[0]\n",
    "        lattice = torch.tensor(lattice_matrix, dtype=torch.float)\n",
    "        \n",
    "        # Get fractional coordinates\n",
    "        inv_lattice = torch.linalg.inv(lattice)\n",
    "        frac_coords = positions @ inv_lattice.T\n",
    "        \n",
    "        # Initialize lists\n",
    "        edge_indices = []\n",
    "        edge_vectors = []\n",
    "        edge_distances = []\n",
    "        \n",
    "        for i in range(n_atoms):\n",
    "            # Calculate distances with PBC\n",
    "            frac_diff = frac_coords - frac_coords[i:i+1]\n",
    "            \n",
    "            # Apply periodic boundary conditions\n",
    "            for dim in range(3):\n",
    "                if pbc[dim]:\n",
    "                    frac_diff[:, dim] = frac_diff[:, dim] - torch.round(frac_diff[:, dim])\n",
    "            \n",
    "            # Convert back to cartesian\n",
    "            cart_diff = frac_diff @ lattice.T\n",
    "            \n",
    "            # Calculate distances\n",
    "            distances = torch.norm(cart_diff, dim=1)\n",
    "            \n",
    "            # Find neighbors within cutoff (excluding self)\n",
    "            mask = (distances > 0.01) & (distances <= cutoff)\n",
    "            neighbors = torch.where(mask)[0]\n",
    "            \n",
    "            for j in neighbors:\n",
    "                edge_indices.append([i, j])\n",
    "                edge_vectors.append(cart_diff[j])\n",
    "                edge_distances.append(distances[j])\n",
    "        \n",
    "        if len(edge_indices) == 0:\n",
    "            # Fallback: connect to nearest neighbors\n",
    "            return self.build_knn_edges(positions, k=12)\n",
    "        \n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        edge_vec = torch.stack(edge_vectors)\n",
    "        edge_dist = torch.tensor(edge_distances, dtype=torch.float)\n",
    "        \n",
    "        return edge_index, edge_vec, edge_dist\n",
    "    \n",
    "    def build_knn_edges(self, positions, k=12):\n",
    "        \"\"\"Build k-nearest neighbor edges (fallback)\"\"\"\n",
    "        from scipy.spatial import cKDTree\n",
    "        \n",
    "        pos_np = positions.numpy()\n",
    "        tree = cKDTree(pos_np)\n",
    "        distances, indices = tree.query(pos_np, k=k+1)  # +1 to exclude self\n",
    "        \n",
    "        edge_indices = []\n",
    "        edge_vectors = []\n",
    "        edge_distances = []\n",
    "        \n",
    "        for i in range(len(pos_np)):\n",
    "            for j_idx, j in enumerate(indices[i]):\n",
    "                if i != j:  # Exclude self\n",
    "                    edge_indices.append([i, j])\n",
    "                    vec = positions[j] - positions[i]\n",
    "                    edge_vectors.append(vec)\n",
    "                    edge_distances.append(distances[i][j_idx])\n",
    "        \n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        edge_vec = torch.stack(edge_vectors)\n",
    "        edge_dist = torch.tensor(edge_distances, dtype=torch.float)\n",
    "        \n",
    "        return edge_index, edge_vec, edge_dist\n",
    "    \n",
    "    def build_angles(self, edge_index, edge_vectors, edge_distances):\n",
    "        \"\"\"Build angle edges for line graph\"\"\"\n",
    "        n_edges = edge_index.shape[1]\n",
    "        \n",
    "        # Build mapping from node to incident edges\n",
    "        node_to_edges = {}\n",
    "        for edge_idx in range(n_edges):\n",
    "            i, j = edge_index[:, edge_idx].tolist()\n",
    "            node_to_edges.setdefault(i, []).append((edge_idx, j, 'out'))\n",
    "            node_to_edges.setdefault(j, []).append((edge_idx, i, 'in'))\n",
    "        \n",
    "        # Find angles (triplets of edges sharing a node)\n",
    "        angle_indices = []\n",
    "        angle_values = []\n",
    "        \n",
    "        for center_node, edges in node_to_edges.items():\n",
    "            # Get all edges incident to this node\n",
    "            for idx1, (edge_idx1, node1, dir1) in enumerate(edges):\n",
    "                for idx2, (edge_idx2, node2, dir2) in enumerate(edges):\n",
    "                    if idx1 >= idx2:\n",
    "                        continue\n",
    "                    \n",
    "                    # The two edges share the center_node\n",
    "                    # Edge1: node1-center_node\n",
    "                    # Edge2: center_node-node2\n",
    "                    \n",
    "                    # Get vectors\n",
    "                    vec1 = edge_vectors[edge_idx1]\n",
    "                    vec2 = edge_vectors[edge_idx2]\n",
    "                    \n",
    "                    # Reverse vector if needed\n",
    "                    if dir1 == 'in':\n",
    "                        vec1 = -vec1\n",
    "                    if dir2 == 'in':\n",
    "                        vec2 = -vec2\n",
    "                    \n",
    "                    # Compute angle\n",
    "                    cos_angle = torch.dot(vec1, vec2) / (torch.norm(vec1) * torch.norm(vec2) + 1e-8)\n",
    "                    angle = torch.acos(torch.clamp(cos_angle, -1.0, 1.0))\n",
    "                    \n",
    "                    angle_indices.append([edge_idx1, edge_idx2])\n",
    "                    angle_values.append(angle)\n",
    "        \n",
    "        if len(angle_indices) == 0:\n",
    "            # Create dummy angles\n",
    "            angle_indices = torch.zeros((2, 1), dtype=torch.long)\n",
    "            angle_values = torch.zeros(1, dtype=torch.float)\n",
    "        else:\n",
    "            angle_indices = torch.tensor(angle_indices, dtype=torch.long).t().contiguous()\n",
    "            angle_values = torch.stack(angle_values)\n",
    "        \n",
    "        return angle_indices, angle_values\n",
    "    \n",
    "    def encode_atoms(self, atomic_numbers):\n",
    "        \"\"\"Encode atomic numbers as features\"\"\"\n",
    "        # Common elements in TMDCs: Mo(42), W(74), S(16), Se(34)\n",
    "        element_embedding = {\n",
    "            42: [1, 0, 0, 0],  # Mo\n",
    "            74: [0, 1, 0, 0],  # W\n",
    "            16: [0, 0, 1, 0],  # S\n",
    "            34: [0, 0, 0, 1],  # Se\n",
    "        }\n",
    "        \n",
    "        features = []\n",
    "        for z in atomic_numbers:\n",
    "            if z.item() in element_embedding:\n",
    "                features.append(element_embedding[z.item()])\n",
    "            else:\n",
    "                # Unknown element (defect)\n",
    "                features.append([0, 0, 0, 0])\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float)\n",
    "    \n",
    "    def gaussian_basis(self, distances, num_centers=20, gamma=0.1):\n",
    "        \"\"\"Gaussian basis expansion for distances\"\"\"\n",
    "        centers = torch.linspace(0, 5.0, num_centers)\n",
    "        expanded = torch.exp(-gamma * (distances.unsqueeze(-1) - centers.unsqueeze(0)) ** 2)\n",
    "        return expanded\n",
    "    \n",
    "    def spherical_bessel_basis(self, angles, num_basis=6):\n",
    "        \"\"\"Spherical Bessel basis for angles\"\"\"\n",
    "        # Simplified version using Fourier basis\n",
    "        k = torch.arange(1, num_basis + 1, dtype=torch.float)\n",
    "        expanded = torch.sin(k.unsqueeze(0) * angles.unsqueeze(-1))\n",
    "        return expanded\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = torch.load(self.processed_paths[idx], weights_only=False)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17cc670-ef77-407c-b126-df2bbf2d2e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset sizes: Train=2077, Val=296, Test=593\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. MAIN EXECUTION SCRIPT\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'data_dir': './dichalcogenides_public',\n",
    "    'structures_dir': './dichalcogenides_public/structures/',\n",
    "    'targets_csv': './dichalcogenides_public/targets.csv',\n",
    "    'batch_size': 1,\n",
    "    'val_split': 0.1,\n",
    "    'test_split': 0.2,\n",
    "    'random_seed': 42,\n",
    "    'epochs': 10\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(config['random_seed'])\n",
    "np.random.seed(config['random_seed'])\n",
    "\n",
    "# Create dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = TMDCDataset(\n",
    "    root='./processed_data',\n",
    "    structures_dir=config['structures_dir'],\n",
    "    targets_csv=config['targets_csv']\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "dataset_size = len(dataset)\n",
    "val_size = int(config['val_split'] * dataset_size)\n",
    "test_size = int(config['test_split'] * dataset_size)\n",
    "train_size = dataset_size - val_size - test_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "print(f\"Dataset sizes: Train={train_size}, Val={val_size}, Test={test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c082a92-a582-47b4-bbdf-50c7ee4d662e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = np.concatenate([val_dataset[i].y.numpy() for i in range(len(val_dataset))])\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d3228e-9438-4cb1-944a-36358dbf1f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2077"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed375412-9cdb-4987-ac8c-da3ae6c234de",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f82071-3615-403c-9167-28ff3a706d77",
   "metadata": {},
   "source": [
    "## Common (utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c055645b-08e4-4231-9334-704b4f6cf975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object(types_dict: Dict[str, type], obj: Union[str, object], base_type: type, default: str):\n",
    "    if obj is None or isinstance(obj, str):\n",
    "        obj = obj or default\n",
    "        return types_dict[obj.lower()]()\n",
    "    elif isinstance(obj, base_type):\n",
    "        return obj\n",
    "    else:\n",
    "        raise RuntimeError(f\"Param should be an instance of base {base_type}, string or None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7107e-df77-4cbf-a1cf-58814d4e2a84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a666d5-ba09-405f-9bba-7f6cce577df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base abstract Activation class\n",
    "\n",
    "class Activation:\n",
    "    NAME = None\n",
    "\n",
    "    def call(self, x):\n",
    "        raise NotImplementedError(\"Call not impelemted\")\n",
    "\n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Derivative not impelemted\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.call(x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82bd78e-6e0c-42b2-8542-d686eddae6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Activation):\n",
    "    NAME = \"linear\"\n",
    "\n",
    "    def call(self, x):\n",
    "        return x\n",
    "\n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73124713-7443-4ce5-9f14-12348036144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    NAME = \"sigmoid\"\n",
    "\n",
    "    def __init__(self, clip_limit: Optional[Union[int, float]] = 250):\n",
    "        self.clip_limit = -clip_limit if clip_limit is not None and clip_limit < 0 else clip_limit\n",
    "\n",
    "    def call(self, x):\n",
    "        x = np.clip(x, -self.clip_limit, self.clip_limit) if self.clip_limit else x\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        return out * (1 - out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd41fc64-e26a-4a69-ad27-dad2cab5fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Activation):\n",
    "    NAME = \"tanh\"\n",
    "\n",
    "    # @njit(cache=True,fastmath=True)\n",
    "    def call(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        return 1. - out**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b3351b-c23a-4af6-8ad3-0eebd1e580f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Activation):\n",
    "    NAME = 'relu'\n",
    "    \n",
    "    def call(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        return (out > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a212b30f-1b77-4bf4-926a-ce85a9557028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiLU(Activation):\n",
    "    NAME = \"silu\"\n",
    "    \n",
    "    def __init__(self, clip_limit: Optional[Union[int, float]] = 250):\n",
    "        self.sigmoid = Sigmoid(clip_limit)\n",
    "        self.x_sigm = None    # bhee\n",
    "\n",
    "    def call(self, x):\n",
    "        self.x_sigm = self.sigmoid(x)\n",
    "        return x * self.x_sigm\n",
    "\n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        return self.x_sigm * (1. - out) + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b21b490c-61ac-4cdb-ae3e-7457e1c1cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StableSoftmax(Activation):\n",
    "    \"\"\"More numerically stable softmax implementation\"\"\"\n",
    "    NAME = 'stable_softmax'\n",
    "\n",
    "    def call(self, x):\n",
    "        stable_x = x - np.max(x, axis=-1, keepdims=True)\n",
    "        exp_x = np.exp(stable_x)\n",
    "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "    def derivative(self, out, *args, **kwargs):\n",
    "        if len(args) > 0:\n",
    "            dout = args[0]\n",
    "        elif 'dout' in kwargs:\n",
    "            dout = kwargs['dout']\n",
    "        else:\n",
    "            raise ValueError(\"dout should be also provided for softmax derivative\")\n",
    "        dx = out * (dout - np.sum(dout * out, axis=-1, keepdims=True))\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbac3ecc-f690-4209-a33f-33f390c5c3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear': <class '__main__.Linear'>, 'sigmoid': <class '__main__.Sigmoid'>, 'tanh': <class '__main__.Tanh'>, 'relu': <class '__main__.ReLU'>, 'silu': <class '__main__.SiLU'>, 'stable_softmax': <class '__main__.StableSoftmax'>}\n"
     ]
    }
   ],
   "source": [
    "# Find all classes based on Activation class\n",
    "ACTIVATIONS = {\n",
    "    v.NAME: v \n",
    "    for v in globals().values() \n",
    "    if isinstance(v, type) and Activation in v.__bases__\n",
    "}\n",
    "\n",
    "print(ACTIVATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb3e70-4761-4147-9617-9f5bd4cd96ee",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0527b8-8bf5-4664-9e89-e1ef2dcca854",
   "metadata": {},
   "source": [
    "### Base Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b1a0ec-fb13-416d-8d1e-3a405b3dbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    def __init__(self, input_size, output_size, activation='linear'):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = get_object(ACTIVATIONS, activation, base_type=Activation, default='linear')\n",
    "        # Train params\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.name = str(uuid4())\n",
    "        self.training = True\n",
    "\n",
    "    def enable_training(self):\n",
    "        self.training = True\n",
    "\n",
    "    def disable_training(self):\n",
    "        self.training = False\n",
    "    \n",
    "    def init_weights(self):\n",
    "        raise NotImplementedError(\"Init weights not impelemted\")\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        raise NotImplementedError(\"Number of parameters not impelemted\")\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Forward not impelemted\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        output = self.forward(*args, **kwargs)\n",
    "        if not self.training:\n",
    "            self.clear_tmp()\n",
    "        return output\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Backward not impelemted\")\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa450cd-9956-4b32-8fbf-680857fee0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayersBlock:\n",
    "    \"\"\" Class for Block of layers \"\"\"\n",
    "    def __init__(self):\n",
    "        self.layers_names: list[str] = []\n",
    "        self.layers: list[BaseLayer] = []\n",
    "        \n",
    "        self._layers_inputs: list[np.ndarray] = []\n",
    "        self._layers_outputs: list[np.ndarray] = []\n",
    "        self._layers_grads: list[tuple[BaseLayer, np.ndarray]] = []\n",
    "        \n",
    "        self.name = str(uuid4())\n",
    "        self.training = True\n",
    "\n",
    "    def enable_training(self):\n",
    "        self.training = True\n",
    "        for l in self.layers:\n",
    "            l.enable_training()\n",
    "\n",
    "    def disable_training(self):\n",
    "        self.training = False\n",
    "        for l in self.layers:\n",
    "            l.disable_training()\n",
    "    \n",
    "    def add_layer(self, layer: BaseLayer, name: str = None):\n",
    "        name = name or layer.name\n",
    "        self.layers_names.append(name)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def add_layers(self, layers: Union[List[Dict[str, BaseLayer]], Dict[str, BaseLayer]]):\n",
    "        if isinstance(layers, dict):\n",
    "            layers = map(lambda x: dict([x]), layers.items())\n",
    "        for layer_dict in layers:\n",
    "            name, layer = next(iter(layer_dict.items()))\n",
    "            self.add_layer(layer, name)\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return sum([l.num_params for l in self.layers])\n",
    "\n",
    "    def _forward_layer(self, layer_name: str, X):\n",
    "        if self.training:\n",
    "            self._layers_inputs.append(X)\n",
    "\n",
    "        layer_idx = self.layers_names.index(layer_name)\n",
    "        output = self.layers[layer_idx].forward(X)\n",
    "        self._layers_outputs.append(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _backward_layer(self, layer_name: str, doutput, calc_grads=True):\n",
    "        layer_idx = self.layers_names.index(layer_name)\n",
    "        layer_input = self._layers_inputs.pop(layer_idx)\n",
    "        layer_output = self._layers_outputs.pop(layer_idx)\n",
    "\n",
    "        dinput, grads = self.layers[layer_idx].backward(layer_input, layer_output, doutput, calc_grads=calc_grads)\n",
    "        \n",
    "        if calc_grads:\n",
    "            if len(self._layers_grads) == len(self.layers):\n",
    "                for i in range(self._layers_grads):\n",
    "                    if self._layers_grads[i][0].name == self.layers[layer_idx].name:\n",
    "                        prev_grads = self._layers_grads[i][1]\n",
    "                        self._layers_grads[i] = (self.layers[layer_idx], grads + prev_grads)\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"Grads not found\")\n",
    "            else:\n",
    "                self._layers_grads.append((self.layers[layer_idx], grads))\n",
    "    \n",
    "        return dinput\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Forward not impelemted\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        output = self.forward(*args, **kwargs)\n",
    "        if not self.training:\n",
    "            self.clear_tmp()\n",
    "        return output\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Backward not impelemted\")\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self._layers_inputs = []\n",
    "        self._layers_outputs = []\n",
    "        self._layers_grads = []\n",
    "        for layer in self.layers:\n",
    "            layer.clear_tmp()\n",
    "\n",
    "    def summary(self, with_name: bool = False, return_array: bool = False):\n",
    "        # Collect info\n",
    "        info = [ # Header\n",
    "            [\"Layer\", \"Input size\", \"Output size\", \"Num params\", \"Activation\"]\n",
    "        ]\n",
    "        if with_name:\n",
    "            info[0].append(\"Unique Name\")\n",
    "        info_len = list(map(len, info[0]))\n",
    "    \n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayersBlock):\n",
    "                layer_info = (layer.__class__.__name__, '-', '-', '-', '-')\n",
    "            else:\n",
    "                layer_info = (\n",
    "                    layer.__class__.__name__, \n",
    "                    layer.input_size,\n",
    "                    layer.output_size,\n",
    "                    layer.num_params,\n",
    "                    layer.activation,\n",
    "                )\n",
    "            if with_name:\n",
    "                layer_info += (layer.name)\n",
    "\n",
    "            layer_info = list(map(str, layer_info))\n",
    "            info.append(layer_info)\n",
    "            \n",
    "            layer_lens = list(map(len, layer_info))\n",
    "            info_len = [max(_prev, _new) for _prev, _new in zip(info_len, layer_lens)]\n",
    "    \n",
    "            if isinstance(layer, LayersBlock):\n",
    "                info.append(layer)\n",
    "\n",
    "        if return_array:\n",
    "            return info\n",
    "        \n",
    "        # Print info\n",
    "        def _print_dash_line():\n",
    "            print(\"+\", end=\"\")\n",
    "            for _len in info_len:\n",
    "                print(\"-\" * (_len + 2), end=\"+\")\n",
    "            print()\n",
    "\n",
    "        def _print_summary(info, with_header=True):\n",
    "            _print_dash_line()\n",
    "            total_params = 0\n",
    "            for row_ind, row_info in enumerate(info):\n",
    "                if isinstance(row_info, LayersBlock):\n",
    "                    block_info = row_info.summary(with_name=with_name, return_array=True)\n",
    "                    total_params += _print_summary(block_info[1:], with_header=False)\n",
    "                else:\n",
    "                    print(\"| \", end=\"\")\n",
    "                    for field, field_len in zip(row_info, info_len):\n",
    "                        print(field.ljust(field_len), end=\" | \") \n",
    "                    print()\n",
    "                    total_params += int(row_info[3]) if row_info[3].isdigit() else 0\n",
    "                if with_header and row_ind == 0:\n",
    "                    _print_dash_line()\n",
    "            _print_dash_line()\n",
    "            return total_params\n",
    "\n",
    "        total_params = _print_summary(info)\n",
    "        print(f\"Total trainable params: {total_params:,}\")\n",
    "        return total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a9365-bc78-472d-978b-b100d5c26cdd",
   "metadata": {},
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963b5c8c-afd6-4cca-8f1b-6c5fb33e33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(BaseLayer):\n",
    "    def init_weights(self):\n",
    "        self.weights = np.random.normal(\n",
    "            scale=2./(self.input_size + self.output_size), \n",
    "            size=(self.input_size, self.output_size)\n",
    "        )\n",
    "        self.bias = np.random.normal(\n",
    "            scale=2/(self.input_size + self.output_size), \n",
    "            size=(1, self.output_size)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return (self.input_size + 1) * self.output_size\n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = np.dot(X, self.weights) + self.bias\n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True):\n",
    "        # Activation function gradient\n",
    "        doutput = doutput * self.activation.derivative(output)\n",
    "        # Next grdients calculation\n",
    "        dinput = np.dot(doutput, self.weights.T)\n",
    "        if calc_grads:\n",
    "            if len(X.shape) > 2:\n",
    "                X = X.reshape(-1, X.shape[-1])\n",
    "                doutput = doutput.reshape(-1, doutput.shape[-1])\n",
    "\n",
    "            dweights = np.dot(X.T, doutput)\n",
    "            dbias = np.sum(doutput, axis=0, keepdims=True)\n",
    "        else:\n",
    "            dweights = dbias = None\n",
    "\n",
    "        return dinput, {\"weights\": dweights, \"bias\": dbias}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd00b5-e673-4452-b893-dfc773609c8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2D Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af20f3ad-8778-48a7-976f-433f6b3b19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_2d_tuple(x):\n",
    "    if isinstance(x, int):\n",
    "        return (x, x)\n",
    "    elif isinstance(x, (tuple, list)):\n",
    "        return (x[0], x[1 if len(x) >= 2 else 0])\n",
    "    else:\n",
    "        raise ValueError(f\"Incorrect value {x} - should be int or tuple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe3fd1b-ff82-423a-845b-2149a156593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base2DLayer(BaseLayer):\n",
    "    def __init__(self, input_size, output_channels, window_size, stride=None, padding=0, activation='linear'):\n",
    "        # input_size: (channels, height, width)\n",
    "        self.input_size = input_size\n",
    "        self.input_channels, self.input_height, self.input_width = input_size\n",
    "\n",
    "        self.window_size = as_2d_tuple(window_size)\n",
    "        self.stride = as_2d_tuple(stride)\n",
    "        self.padding = as_2d_tuple(padding)\n",
    "\n",
    "        # Calculate output dimensions\n",
    "        if isinstance(output_channels, int):\n",
    "            self.output_channels = output_channels\n",
    "            self.output_height = (self.input_height + 2 * self.padding[0] - self.window_size[0]) // self.stride[0] + 1\n",
    "            self.output_width = (self.input_width + 2 * self.padding[1] - self.window_size[1]) // self.stride[1] + 1\n",
    "        elif isinstance(output_channels, (tuple, list)) and len(output_channels) == 3:\n",
    "            self.output_channels, self.output_height, self.output_width = output_channels\n",
    "        else:\n",
    "            raise ValueError(\"output_channels should be int or tuple\")\n",
    "\n",
    "        self.output_size = (self.output_channels, self.output_height, self.output_width)\n",
    "\n",
    "        # Initialize base class\n",
    "        super().__init__(self.input_size, self.output_size, activation)\n",
    "\n",
    "    def _pad_input(self, X, padding=None):\n",
    "        \"\"\"Apply padding to input\"\"\"\n",
    "        padding = padding or self.padding\n",
    "        if padding[0] == 0 and padding[1] == 0:\n",
    "            return X\n",
    "    \n",
    "        return np.pad(X, \n",
    "            (\n",
    "                (0, 0), (0, 0), # Batch and channels without pad\n",
    "                (padding[0], padding[0]),\n",
    "                (padding[1], padding[1]) \n",
    "            ),\n",
    "            mode='constant'\n",
    "        )\n",
    "\n",
    "    def _get_receptive_field_borders(self, i, j):\n",
    "        h_start = i * self.stride[0]\n",
    "        h_end = h_start + self.window_size[0]\n",
    "        w_start = j * self.stride[1]\n",
    "        w_end = w_start + self.window_size[1]\n",
    "        return (h_start, w_start), (h_end, w_end)\n",
    "\n",
    "    def _get_patches_vectorized(self, X):\n",
    "        \"\"\"Memory-efficient patch extraction using strided views\"\"\"\n",
    "        batch_size, channels, height, width = X.shape\n",
    "        \n",
    "        # Create strided view (no memory copy)\n",
    "        shape = (batch_size, channels, \n",
    "                 self.output_height, self.output_width,\n",
    "                 self.window_size[0], self.window_size[1])\n",
    "        \n",
    "        strides = (X.strides[0], X.strides[1],\n",
    "                   self.stride[0] * X.strides[2],\n",
    "                   self.stride[1] * X.strides[3],\n",
    "                   X.strides[2], X.strides[3])\n",
    "        \n",
    "        return np.lib.stride_tricks.as_strided(\n",
    "            X, shape=shape, strides=strides, writeable=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a469aee-4593-4329-875b-9dc33f072818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(Base2DLayer):\n",
    "    def __init__(self, input_size, output_channels, kernel_size, stride=1, padding=0, activation='linear'):\n",
    "        super().__init__(input_size, output_channels, kernel_size, stride, padding, activation)\n",
    "\n",
    "        self.kernel_size = self.window_size\n",
    "        # Store for backward pass\n",
    "        self._patches = None\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # He initialization\n",
    "        kernel_params = self.window_size[0] * self.window_size[1]\n",
    "        scale = np.sqrt(2.0/ (self.input_channels * kernel_params))\n",
    "\n",
    "        self.weights = np.random.normal(\n",
    "            scale=scale,\n",
    "            size=(\n",
    "                self.output_channels, \n",
    "                self.input_channels, \n",
    "                *self.window_size\n",
    "            )\n",
    "        )\n",
    "        self.bias = np.random.normal(scale=scale, size=self.output_channels)\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return self.weights.size + self.bias.size\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass for Conv2D\n",
    "        X shape: (batch_size, input_channels, input_height, input_width)\n",
    "        Returns: (batch_size, output_channels, output_height, output_width)\n",
    "        \"\"\"\n",
    "        X_padded = self._pad_input(X)\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        # Reshape input for vectorized convolution\n",
    "        patches = np.zeros(\n",
    "            (\n",
    "                batch_size, self.output_height, self.output_width, \n",
    "                self.input_channels, self.window_size[0], self.window_size[1]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Extract all patches at once using vectorized indexing\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                (h_start, w_start), (h_end, w_end) = self._get_receptive_field_borders(i, j)\n",
    "                patches[:, i, j, :, :, :] = X_padded[:, :, h_start:h_end, w_start:w_end]\n",
    "        \n",
    "        # Vectorized matrix multiplication\n",
    "        self._patches = patches.reshape(batch_size, self.output_height, self.output_width, -1)\n",
    "        weights_flat = self.weights.reshape(self.output_channels, -1)\n",
    "        \n",
    "        output = np.einsum('bhwi,oi->bhwo', self._patches, weights_flat)\n",
    "        output = output.transpose(0, 3, 1, 2)  # Rearrange to (batch, channels, height, width)\n",
    "        output += self.bias[None, :, None, None]\n",
    "        \n",
    "        return self.activation(output)\n",
    "    \n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True):\n",
    "        \"\"\"\n",
    "        Backward pass for Conv2D\n",
    "        X: Previous input to the layer\n",
    "        output: Output from forward pass (after activation)\n",
    "        doutput: Gradient from next layer\n",
    "        Returns: dinput and dict to update weights\n",
    "        \"\"\"\n",
    "        doutput = doutput * self.activation.derivative(output)\n",
    "        batch_size = X.shape[0]\n",
    "    \n",
    "        # 1. Extract patches (reuse your forward logic)\n",
    "        doutput_flat = doutput.transpose(0, 2, 3, 1).reshape(-1, self.output_channels)\n",
    "\n",
    "        if calc_grads:\n",
    "            patches_flat = self._patches.reshape(batch_size * self.output_height * self.output_width, -1)\n",
    "            # 2. Compute gradients\n",
    "            dweights = doutput_flat.T @ patches_flat\n",
    "            dweights = dweights.reshape(self.weights.shape)\n",
    "            dweights /= batch_size\n",
    "        \n",
    "            dbias = np.sum(doutput, axis=(0, 2, 3)) / batch_size\n",
    "        else:\n",
    "            dweights = dbias = None\n",
    "        \n",
    "        # 3. Compute dinput using col2im\n",
    "        weights_flat = self.weights.reshape(self.output_channels, -1)\n",
    "        dX_col = doutput_flat @ weights_flat\n",
    "        dX_col = dX_col.reshape(batch_size, self.output_height, self.output_width, self.input_channels, *self.window_size)\n",
    "\n",
    "        X_padded_shape = (\n",
    "            batch_size, self.input_channels, \n",
    "            self.input_height + self.padding[0] * 2, \n",
    "            self.input_width + self.padding[1] * 2\n",
    "        )\n",
    "        dinput = np.zeros(X_padded_shape, dtype=dX_col.dtype)\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                (h_start, w_start), (h_end, w_end) = self._get_receptive_field_borders(i, j)\n",
    "                dinput[:, :, h_start:h_end, w_start:w_end] += dX_col[:, i, j, :, :, :]\n",
    "\n",
    "        # # Remove padding from dinput gradient\n",
    "        if self.padding[0] > 0 and self.padding[1] > 0:\n",
    "            dinput = dinput[:, :, self.padding[0]:-self.padding[0], self.padding[1]:-self.padding[1]]\n",
    "        elif self.padding[0] > 0:\n",
    "            dinput = dinput[:, :, self.padding[0]:-self.padding[0], :]\n",
    "        elif self.padding[1] > 0:\n",
    "            dinput = dinput[:, :, :, self.padding[1]:-self.padding[1]]\n",
    "                \n",
    "        return dinput, {\"weights\": dweights, \"bias\": dbias}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self._patches = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3f3d355-0d98-4017-b240-a14a2293763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D(Base2DLayer):\n",
    "    def __init__(self, input_size, pool_size=2, stride=None, padding=0):\n",
    "        \"\"\"\n",
    "        Max Pooling 2D Layer\n",
    "        \n",
    "        Args:\n",
    "            pool_size: int or tuple, size of the pooling window\n",
    "            stride: int or tuple, stride of the pooling operation. If None, defaults to pool_size\n",
    "            padding: int or tuple, padding to apply to input\n",
    "        \"\"\"\n",
    "        super().__init__(input_size, input_size[0], pool_size, stride or pool_size, padding)\n",
    "\n",
    "        self.pool_size = self.window_size        \n",
    "        # Store for backward pass\n",
    "        self.max_mask = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Pooling layer have no trainable parameters\"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Pooling layer have no trainable parameters\"\"\"\n",
    "        return 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass for MaxPool2D\n",
    "        \n",
    "        Args:\n",
    "            X: input data with shape: (batch_size, channels, height, width)\n",
    "        Returns: \n",
    "            output with shape (batch_size, channels, output_height, output_width)\n",
    "        \"\"\"\n",
    "        batch_size, channels, height, width = X.shape\n",
    "        X_padded = self._pad_input(X)\n",
    "        # Use strided view for efficient patch extraction\n",
    "        patches = self._get_patches_vectorized(X_padded)\n",
    "        # Reshape for vectorized max operation\n",
    "        patches_reshaped = patches.reshape(\n",
    "            batch_size, channels, self.output_height, self.output_width, -1\n",
    "        )\n",
    "        # Find max values and their indices\n",
    "        output = np.max(patches_reshaped, axis=-1)\n",
    "        # Create mask for backward pass\n",
    "        max_mask = (patches_reshaped == output[..., np.newaxis])\n",
    "        # Store for backward pass\n",
    "        self.max_mask = max_mask.reshape(patches.shape)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True):\n",
    "        \"\"\"\n",
    "        Backward pass for MaxPool2D\n",
    "        \n",
    "        Args:\n",
    "            X: Previous input to the layer \n",
    "            output: Output from forward pass (after activation), not used\n",
    "            doutput: Gradient from next layer        \n",
    "        Returns:\n",
    "            dinput: Input gradient, shape (batch_size, channels, input_height, input_width)\n",
    "        \"\"\"\n",
    "        batch_size, channels, height, width = X.shape\n",
    "        # Initialize gradient with respect to input (padded)\n",
    "        dinput_padded = np.zeros((batch_size, channels, height + self.padding[0] * 2, width + self.padding[1] * 2))\n",
    "\n",
    "        # Vectorized gradient distribution using the mask\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                (h_start, w_start), (h_end, w_end) = self._get_receptive_field_borders(i, j)\n",
    "                # Get the mask for this window position\n",
    "                window_mask = self.max_mask[:, :, i, j, :, :]\n",
    "                # Distribute gradients using vectorized operations\n",
    "                dinput_padded[:, :, h_start:h_end, w_start:w_end] += (\n",
    "                    doutput[:, :, i, j][:, :, np.newaxis, np.newaxis] * window_mask\n",
    "                )\n",
    "        \n",
    "        # Remove padding from gradient\n",
    "        if self.padding[0] > 0 or self.padding[1] > 0:\n",
    "            if self.padding[0] > 0 and self.padding[1] > 0:\n",
    "                dinput = dinput_padded[:, :, self.padding[0]:-self.padding[0], self.padding[1]:-self.padding[1]]\n",
    "            elif self.padding[0] > 0:\n",
    "                dinput = dinput_padded[:, :, self.padding[0]:-self.padding[0], :]\n",
    "            else:\n",
    "                dinput = dinput_padded[:, :, :, self.padding[1]:-self.padding[1]]\n",
    "        else:\n",
    "            dinput = dinput_padded\n",
    "        \n",
    "        return dinput, {}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self.max_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c4aa035-4aee-4035-b722-7cb20f2639c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(BaseLayer):\n",
    "    def init_weights(self):\n",
    "        \"\"\"Flatten layer have no trainable parameters\"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Flatten layer have no trainable parameters\"\"\"\n",
    "        return 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        output_size = self.output_size if isinstance(self.output_size, tuple) else (self.output_size,)\n",
    "        return X.reshape((X.shape[0], *output_size))\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True):\n",
    "        input_size = self.input_size if isinstance(self.input_size, tuple) else (self.input_size,)\n",
    "        dinput = doutput.reshape((doutput.shape[0], *input_size))\n",
    "        return dinput, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8e97f43-bda5-438b-b316-a74d4e5a56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose(Base2DLayer):\n",
    "    def __init__(self, input_size, output_channels, kernel_size, stride=1, padding=0, activation='linear'):\n",
    "        \"\"\"\n",
    "        Transposed Convolution 2D Layer (Deconvolution)\n",
    "        \n",
    "        Args:\n",
    "            input_size: (input_channels, input_height, input_width)\n",
    "            output_channels: number of output channels\n",
    "            kernel_size: size of the convolution kernel\n",
    "            stride: stride of the convolution\n",
    "            padding: padding applied to input\n",
    "            output_padding: additional padding added to output\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate output dimensions for transposed convolution\n",
    "        kernel_size = as_2d_tuple(kernel_size)\n",
    "        stride = as_2d_tuple(stride)\n",
    "        padding = as_2d_tuple(padding)\n",
    "\n",
    "        output_height = (input_size[1] - 1) * stride[0] + kernel_size[0] - 2 * padding[0] + max(0, stride[0] - 1)\n",
    "        output_width = (input_size[2] - 1) * stride[1] + kernel_size[1] - 2 * padding[1] + max(0, stride[1] - 1)\n",
    "        output_size = (output_channels, output_height, output_width)\n",
    "\n",
    "        # Initialize base class with modified parameters\n",
    "        super().__init__(input_size, output_size, kernel_size, stride, padding, activation)\n",
    "        \n",
    "        # Store for backward pass\n",
    "        self._patches = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        # He initialization\n",
    "        kernel_params = self.window_size[0] * self.window_size[1]\n",
    "        scale = np.sqrt(2.0 / (self.output_channels * kernel_params))\n",
    "\n",
    "        self.weights = np.random.normal(\n",
    "            scale=scale,\n",
    "            size=(\n",
    "                self.output_channels,\n",
    "                self.input_channels,\n",
    "                *self.window_size\n",
    "            )\n",
    "        )\n",
    "        self.bias = np.random.normal(scale=scale, size=self.output_channels)\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return self.weights.size + self.bias.size\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass for Conv2DTranspose\n",
    "        X shape: (batch_size, input_channels, input_height, input_width)\n",
    "        Returns: (batch_size, output_channels, output_height, output_width)\n",
    "        \"\"\"\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        # Use im2col technique for transposed convolution\n",
    "        # Expand input according to stride (28 * 2 = 56)\n",
    "        X_exp_shape = (self.input_height * self.stride[0], self.input_width * self.stride[1])\n",
    "        X_expanded = np.zeros((batch_size, self.input_channels, *X_exp_shape)) \n",
    "        X_expanded[:, :, ::self.stride[0], ::self.stride[1]] = X\n",
    "        \n",
    "        # Apply padding to expanded input\n",
    "        X_padded = self._pad_input(X_expanded) # pad 1 -> (58, 58)\n",
    "        \n",
    "        # Perform regular convolution on expanded and padded input\n",
    "        patches_shape = (\n",
    "            batch_size, \n",
    "            X_padded.shape[2] - self.window_size[0] + 1,  # (56, 56)\n",
    "            X_padded.shape[3] - self.window_size[1] + 1, \n",
    "            self.input_channels, self.window_size[0], self.window_size[1]\n",
    "        )\n",
    "        patches_strides = (\n",
    "            X_padded.strides[0], X_padded.strides[2],\n",
    "            X_padded.strides[3], X_padded.strides[1],\n",
    "            X_padded.strides[2], X_padded.strides[3],\n",
    "        )\n",
    "        patches = np.lib.stride_tricks.as_strided(X_padded, shape=patches_shape, strides=patches_strides)        \n",
    "        # Vectorized matrix multiplication\n",
    "        self._patches = patches.reshape(batch_size, patches_shape[1], patches_shape[2], -1)\n",
    "        weights_flat = self.weights.reshape(self.output_channels, -1)\n",
    "        \n",
    "        output = np.einsum('bhwi,oi->bhwo', self._patches, weights_flat)\n",
    "        output = output.transpose(0, 3, 1, 2)\n",
    "        output += self.bias[None, :, None, None]\n",
    "        \n",
    "        return self.activation(output)\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads=True):\n",
    "        \"\"\"\n",
    "        Optimized backward pass using matrix operations\n",
    "        \"\"\"       \n",
    "        doutput = doutput * self.activation.derivative(output)\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        patches_flat = self._patches.reshape(batch_size * self._patches.shape[1] * self._patches.shape[1], -1)  # (N*oh*ow, in_ch*kH*kW)\n",
    "        doutput_flat = doutput.transpose(0, 2, 3, 1).reshape(-1, self.output_channels)  # (N*oh*ow, out_ch)\n",
    "\n",
    "        if calc_grads:\n",
    "            dweights = doutput_flat.T @ patches_flat  # (out_ch, in_ch*kH*kW)\n",
    "            dweights = dweights.reshape(self.weights.shape)\n",
    "            dweights /= batch_size\n",
    "            dbias = np.sum(doutput, axis=(0,2,3)) / batch_size\n",
    "        else:\n",
    "            dweights = None\n",
    "            dbias = None\n",
    "    \n",
    "        # 3) gradient wrt upsampled+padded input:\n",
    "        weights_flat = self.weights.reshape(self.output_channels, -1)  # (out_ch, in_ch*kH*kW)\n",
    "        dX_col = doutput_flat @ weights_flat  # (N*oh*ow, in_ch*kH*kW)\n",
    "        dX_col = dX_col.reshape(batch_size, self.output_height, self.output_width, self.input_channels, *self.window_size)\n",
    "\n",
    "        X_padded_shape = (\n",
    "            batch_size, self.input_channels, \n",
    "            self.input_height * self.stride[0] + self.padding[0] * 2,\n",
    "            self.input_width  * self.stride[1] + self.padding[1] * 2\n",
    "        )\n",
    "        dinput_expanded = np.zeros(X_padded_shape, dtype=dX_col.dtype)\n",
    "        for i in range(self.window_size[0]):\n",
    "            for j in range(self.window_size[1]):\n",
    "                dinput_expanded[:, :, i:i+self.output_height, j:j+self.output_width] += \\\n",
    "                    dX_col[:, :, :, :, i, j].transpose(0, 3, 1, 2)\n",
    "\n",
    "        # # Remove padding from dinput gradient\n",
    "        if self.padding[0] > 0 and self.padding[1] > 0:\n",
    "            dinput_expanded = dinput_expanded[:, :, self.padding[0]:-self.padding[0], self.padding[1]:-self.padding[1]]\n",
    "        elif self.padding[0] > 0:\n",
    "            dinput_expanded = dinput_expanded[:, :, self.padding[0]:-self.padding[0], :]\n",
    "        elif self.padding[1] > 0:\n",
    "            dinput_expanded = dinput_expanded[:, :, :, self.padding[1]:-self.padding[1]]\n",
    "    \n",
    "        dinput = dinput_expanded[:, :, ::self.stride[0], ::self.stride[1]]\n",
    "        return dinput, {\"weights\": dweights, \"bias\": dbias}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self._patches = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d6dc7-12d0-4746-ba31-a44019cf72a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Transformer layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f07edd5-18a8-413c-b888-aec32dc4d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(BaseLayer):\n",
    "    def __init__(self, input_size, max_seq_length=128):\n",
    "        super().__init__(input_size, input_size, activation=None)\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self._calc_pos_encoding()\n",
    "\n",
    "    def _calc_pos_encoding(self):\n",
    "        # Generate positional encoding\n",
    "        position = np.arange(self.max_seq_length)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, self.input_size, 2) * -(np.log(10000.0) / self.input_size))\n",
    "        \n",
    "        self.pos_encoding = np.zeros((1, self.max_seq_length, self.input_size))\n",
    "        self.pos_encoding[0, :, 0::2] = np.sin(position * div_term)\n",
    "        self.pos_encoding[0, :, 1::2] = np.cos(position * div_term)\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        seq_length = X.shape[1]        \n",
    "        output = X + self.pos_encoding[:, :seq_length, :]\n",
    "        return output\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads=True):\n",
    "        return doutput, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0174d791-10c5-4cde-a7ff-918dda86a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(BaseLayer):\n",
    "    def __init__(self, input_size, eps=1e-5):\n",
    "        super().__init__(input_size, input_size, activation=None)\n",
    "        self.eps = eps\n",
    "        # For backward pass\n",
    "        self.mu = None\n",
    "        self.std = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.weights = np.ones((1, 1, self.input_size)) # gamma\n",
    "        self.bias = np.zeros((1, 1, self.input_size))   # beta\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 2 * self.input_size\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = np.mean(X, axis=-1, keepdims=True)\n",
    "        var = np.var(X, axis=-1, keepdims=True)\n",
    "        self.mu = (X - mean)\n",
    "        self.std = np.sqrt(var + self.eps)\n",
    "    \n",
    "        # Normalize\n",
    "        X_normalized = self.mu / self.std\n",
    "        output = self.weights * X_normalized + self.bias\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads=True):\n",
    "        X_normalized = self.mu / self.std\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        if calc_grads:\n",
    "            dgamma = np.sum(doutput * X_normalized, axis=(0,1), keepdims=True)\n",
    "            dbeta = np.sum(doutput, axis=(0,1), keepdims=True)\n",
    "        else:\n",
    "            dgamma, dbeta = None, None\n",
    "\n",
    "        # Gradient through normalization        \n",
    "        dX_normalized = doutput * self.weights / self.std\n",
    "        dinput = dX_normalized - (\n",
    "            np.sum(dX_normalized, axis=-1, keepdims=True) +\n",
    "            self.mu * np.sum(dX_normalized * self.mu / self.std**2, axis=-1, keepdims=True)\n",
    "        ) / self.input_size\n",
    "\n",
    "        return dinput, {\"weights\": dgamma, \"bias\": dbeta}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self.mu = None\n",
    "        self.std = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd3c9aad-a366-469f-bcf1-231a97191daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(BaseLayer):\n",
    "    def __init__(self, dropout_rate=0.1):\n",
    "        super().__init__(input_size=None, output_size=None, activation=None)\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        if not (0 <= self.dropout_rate < 1):\n",
    "            raise ValueError(\"Dropout rate should be in interval [0, 1)\")\n",
    "\n",
    "        self.mask = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        if not self.training or self.dropout_rate <= 0.0:\n",
    "            return X\n",
    "\n",
    "        self.mask = (np.random.rand(*X.shape) >= self.dropout_rate).astype(X.dtype)\n",
    "        # Inverted Dropout\n",
    "        out = X * self.mask / (1.0 - self.dropout_rate)\n",
    "        return out\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads=True):\n",
    "        if self.mask is None:\n",
    "            return doutput, {}\n",
    "\n",
    "        dinput = doutput * self.mask / (1.0 - self.dropout_rate)\n",
    "        return dinput, {}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self.mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aa9fb65-8019-40af-8813-a1a74cb5973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(BaseLayer):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention implemented with numpy.\n",
    "    - input X: (B, S, D_in)\n",
    "    - projects Q,K,V: (B, S, D_out)\n",
    "    - split into H heads with head_dim = D_out // H\n",
    "    - compute scaled dot-product attention for each head\n",
    "    - combine heads and final linear projection to (B, S, D_out)\n",
    "    - supports optional mask (broadcastable to (B, H, S, S) or (B, S, S))\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, num_heads=8, mask=None, activation='linear'):\n",
    "        self._weights_names = (\"attention\", \"weights\")\n",
    "        # Инициализируются 3 матрицы весов для attention:\n",
    "        # 1. Веса для query (q)\n",
    "        # 2. Веса для key (k)\n",
    "        # 3. Веса для value (v)\n",
    "        # Таже инициализируется ещё одна матрица весов (weights) для выхода\n",
    "        self._inner_names = (\"q\", \"k\", \"v\")\n",
    "\n",
    "        self.num_heads = int(num_heads)\n",
    "        if output_size % self.num_heads != 0:\n",
    "            raise ValueError(\"output_size must be divisible by num_heads\")\n",
    "\n",
    "        self.head_dim = output_size // self.num_heads\n",
    "\n",
    "        if mask is not None:\n",
    "            # Allowed mask shapes (S,S), (B,S,S) or already (B,H,S,S)\n",
    "            if mask.ndim == 2:\n",
    "                mask = mask[None, None, :, :]  # (1,1,S,S)\n",
    "            elif mask.ndim == 3:\n",
    "                mask = mask[:, None, :, :]    # (B,1,S,S)\n",
    "            elif mask.ndim != 4:\n",
    "                raise ValueError(\"mask must be 2D, 3D or 4D\")\n",
    "            self.mask = mask\n",
    "        else:\n",
    "            self.mask = None\n",
    "\n",
    "        self.softmax = StableSoftmax()\n",
    "\n",
    "        super().__init__(input_size, output_size, activation=activation)\n",
    "        # caches used for backward\n",
    "        self._cache = {}\n",
    "\n",
    "    def init_weights(self):\n",
    "        num_inner = (len(self._inner_names),) if self._inner_names is not None else tuple()\n",
    "        attention_scale = 2./(self.input_size + self.output_size)\n",
    "        weights_scale = 2./(self.output_size + self.output_size)\n",
    "    \n",
    "        self.attention = np.random.normal(\n",
    "            scale=attention_scale, size=num_inner + (self.input_size, self.output_size)\n",
    "        )\n",
    "        self.weights = np.random.normal(\n",
    "            scale=weights_scale, size=(self.output_size, self.output_size)\n",
    "        )\n",
    "\n",
    "    def __getattr__(self, attr: str):\n",
    "        # Define __getattr__ to get needed weights like self.attention_q\n",
    "        propobj = getattr(self.__class__, attr, None)\n",
    "        if isinstance(propobj, property):\n",
    "            return propobj.fget(self)\n",
    "\n",
    "        if not self._inner_names:\n",
    "            return\n",
    "\n",
    "        split_attr = attr.rsplit('_', 1)\n",
    "        if len(split_attr) != 2:\n",
    "            return \n",
    "\n",
    "        weights_attr, inner_name = split_attr\n",
    "        if weights_attr in self._weights_names and inner_name in self._inner_names:\n",
    "            weights_idx = self._inner_names.index(inner_name)\n",
    "            return getattr(self, weights_attr)[weights_idx]\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        # total number of scalar params\n",
    "        return self.attention.size + self.weights.size\n",
    "\n",
    "    def _split_heads(self, X):\n",
    "        # X: (B, S, output_size) -> (B, num_heads, S, head_dim)\n",
    "        B, S, _ = X.shape\n",
    "        return X.reshape(B, S, self.num_heads, self.head_dim).transpose(0, 2, 1, 3)\n",
    "\n",
    "    def _combine_heads(self, Xh):\n",
    "        # Xh: (B, num_heads, S, head_dim) -> (B, S, output_size)\n",
    "        B, _, S, _ = Xh.shape\n",
    "        return Xh.transpose(0, 2, 1, 3).reshape(B, S, self.num_heads * self.head_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: (B, S, D_in)\n",
    "        mask: optional, broadcastable to (B, H, S, S) or (B, S, S) or (S,S)\n",
    "              mask entries with 0 will be masked (i.e., prevented from attending)\n",
    "        Returns:\n",
    "            output: (B, S, D_out)\n",
    "        \"\"\"\n",
    "        batch_size, seq_size, _ = X.shape\n",
    "\n",
    "        # Linear projections to Q, K, V: (batch_size, seq_size, output_size)\n",
    "        Q = np.dot(X, self.attention_q)\n",
    "        K = np.dot(X, self.attention_k)\n",
    "        V = np.dot(X, self.attention_v)\n",
    "\n",
    "        # Split into heads: (batch_size, num_heads, seq_size, head_dim)\n",
    "        Qh = self._split_heads(Q)\n",
    "        Kh = self._split_heads(K)\n",
    "        Vh = self._split_heads(V)\n",
    "\n",
    "        # Attention scores: (batch_size, num_heads, seq_size, seq_size)\n",
    "        scores = np.matmul(Qh, Kh.transpose(0, 1, 3, 2)) / np.sqrt(self.head_dim)\n",
    "\n",
    "        # Apply mask (if provided)\n",
    "        if self.mask is not None:\n",
    "            # broadcast to (batch_size, num_heads, seq_size, seq_size)\n",
    "            mask = np.broadcast_to(self.mask, (batch_size, self.num_heads, seq_size, seq_size))\n",
    "            scores = np.where(mask, scores, -1e9)\n",
    "\n",
    "        # Softmax over keys axis\n",
    "        attn = self.softmax(scores)\n",
    "\n",
    "        # Attention output: (batch_size, num_heads, seq_size, head_dim)\n",
    "        context_h = np.matmul(attn, Vh)\n",
    "\n",
    "        # Combine heads: (batch_size, seq_size, output_size)\n",
    "        context = self._combine_heads(context_h)\n",
    "\n",
    "        # final linear projection: (batch_size, seq_size, output_size)\n",
    "        out = np.dot(context, self.weights)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        # Cache required tensors for backward pass\n",
    "        self._cache = {\n",
    "            'Qh': Qh, 'Kh': Kh, 'Vh': Vh,\n",
    "            'attn': attn, 'context': context\n",
    "        }\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True):\n",
    "        \"\"\"\n",
    "        X: original input (B, S, D_in)\n",
    "        output: forward(X) result (post-activation)\n",
    "        doutput: gradient flowing from upper layers, shape (B, S, D_out)\n",
    "        Returns:\n",
    "            dinput: (B, S, D_in)\n",
    "            grads: dict with parameter gradients (weights and biases)\n",
    "        \"\"\"\n",
    "        # Retrieve cache\n",
    "        if not self._cache:\n",
    "            raise RuntimeError(\"No forward cache found. Run forward before backward.\")\n",
    "\n",
    "        batch_size, seq_size, _ = X.shape\n",
    "\n",
    "        Qh, Kh, Vh = self._cache['Qh'], self._cache['Kh'], self._cache['Vh']\n",
    "        attn = self._cache['attn']\n",
    "        context = self._cache['context']\n",
    "\n",
    "        # Gradient through final activation\n",
    "        dpre = doutput * self.activation.derivative(output)\n",
    "        dpre_flat = dpre.reshape(batch_size * seq_size, self.output_size)\n",
    "\n",
    "        if calc_grads:\n",
    "            context_flat = context.reshape(batch_size * seq_size, self.output_size)\n",
    "            dweights = np.dot(context_flat.T, dpre_flat)\n",
    "        else:\n",
    "            dweights = None\n",
    "\n",
    "        # dcontext from final linear: (batch_size, seq_size, output_size)\n",
    "        dcontext = np.dot(dpre_flat, self.weights.T).reshape(batch_size, seq_size, self.output_size)\n",
    "        # split heads to (batch_size, num_heads, seq_size, head_dim)\n",
    "        dcontext_h = self._split_heads(dcontext)\n",
    "\n",
    "        # Gradients w.r.t attention weights and Vh\n",
    "        dattention = np.matmul(dcontext_h, Vh.transpose(0,1,3,2))  \n",
    "        dVh = np.matmul(attn.transpose(0,1,3,2), dcontext_h)     \n",
    "    \n",
    "        # Softmax backward\n",
    "        dscores = self.softmax.derivative(attn, dout=dattention) / np.sqrt(self.head_dim)\n",
    "\n",
    "        # Gradients for Qh and Kh from scores\n",
    "        dQh = np.matmul(dscores, Kh)                     \n",
    "        dKh = np.matmul(dscores.transpose(0,1,3,2), Qh)\n",
    "\n",
    "        # Combine head-gradients: (batch_size, seq_size, output_size)\n",
    "        dQ = self._combine_heads(dQh)\n",
    "        dK = self._combine_heads(dKh)\n",
    "        dV = self._combine_heads(dVh)\n",
    "\n",
    "        # Gradients to projection weights: Q = X @ Wq + bq\n",
    "        X_flat = X.reshape(batch_size * seq_size, self.input_size)\n",
    "        dQ_flat = dQ.reshape(batch_size * seq_size, self.output_size)\n",
    "        dK_flat = dK.reshape(batch_size * seq_size, self.output_size)\n",
    "        dV_flat = dV.reshape(batch_size * seq_size, self.output_size)\n",
    "\n",
    "        if calc_grads:\n",
    "            dattention_q = np.dot(X_flat.T, dQ_flat)[None, :]\n",
    "            dattention_k = np.dot(X_flat.T, dK_flat)[None, :]\n",
    "            dattention_v = np.dot(X_flat.T, dV_flat)[None, :]\n",
    "            dattention = np.concatenate([dattention_q, dattention_k, dattention_v], axis=0)\n",
    "        else:\n",
    "            dattention_q = dattention_k = dattention_v = None\n",
    "\n",
    "        # Gradients w.r.t X: contributions from Q,K,V projections\n",
    "        dinput_q = np.dot(dQ_flat, self.attention_q.T).reshape(batch_size, seq_size, self.input_size)\n",
    "        dinput_k = np.dot(dK_flat, self.attention_k.T).reshape(batch_size, seq_size, self.input_size)\n",
    "        dinput_v = np.dot(dV_flat, self.attention_v.T).reshape(batch_size, seq_size, self.input_size)\n",
    "\n",
    "        # Sum contributions\n",
    "        dinput = dinput_q + dinput_k + dinput_v\n",
    "\n",
    "        return dinput, {'attention': dattention, 'weights': dweights}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        # clear cached tensors\n",
    "        self._cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bc82ccd-bbe4-4ad1-9ec1-8173ad36b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(LayersBlock):\n",
    "    def __init__(\n",
    "            self, input_size, num_heads=8, mask=None, \n",
    "            ff_hidden_size=256, ff_hidden_act='relu', ff_activation='linear', dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add_layer(\n",
    "            MultiHeadAttention(input_size, input_size, num_heads, mask), name=\"attention\"\n",
    "        )\n",
    "        self.add_layer(\n",
    "            Dropout(dropout), name=\"dropout_attention\"\n",
    "        )\n",
    "        self.add_layer(\n",
    "            LayerNormalization(input_size), name=\"layer_norm_attention\"\n",
    "        )\n",
    "        self.add_layer(\n",
    "            Dense(input_size, ff_hidden_size, activation=ff_hidden_act), name=\"mlp_hidden\"\n",
    "        )\n",
    "        self.add_layer(\n",
    "            Dense(ff_hidden_size, input_size, activation=ff_activation), name=\"mlp_out\"\n",
    "        )\n",
    "        self.add_layer(\n",
    "            Dropout(dropout), name=\"dropout_mlp\"\n",
    "        )\n",
    "        self.add_layer(\n",
    "            LayerNormalization(input_size), name=\"layer_norm_mlp\"\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, seq_len, _ = X.shape\n",
    "\n",
    "        ## First sublayer: self attion \n",
    "        attention = self._forward_layer('attention', X)\n",
    "        attention = self._forward_layer('dropout_attention', attention)\n",
    "        attention = self._forward_layer('layer_norm_attention', X + attention)\n",
    "        \n",
    "        mlp_output = self._forward_layer('mlp_hidden', attention)\n",
    "        mlp_output = self._forward_layer('mlp_out', mlp_output)        \n",
    "        mlp_output = self._forward_layer('dropout_mlp', mlp_output)\n",
    "        output = self._forward_layer('layer_norm_mlp', attention + mlp_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads=True):\n",
    "        doutput = self._backward_layer('layer_norm_mlp', doutput, calc_grads=calc_grads)\n",
    "        dmlp = self._backward_layer('dropout_mlp', doutput, calc_grads=calc_grads)\n",
    "        dmlp = self._backward_layer('mlp_out', dmlp, calc_grads=calc_grads)\n",
    "        dmlp = self._backward_layer('mlp_hidden', dmlp, calc_grads=calc_grads)\n",
    "\n",
    "        dattention = self._backward_layer('layer_norm_attention', doutput + dmlp, calc_grads=calc_grads)\n",
    "        dattention = self._backward_layer('dropout_attention', dattention, calc_grads=calc_grads)\n",
    "        dinput = self._backward_layer('attention', dattention, calc_grads=calc_grads)\n",
    "        dinput += dattention\n",
    "        return dinput, self._layers_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47a58997-e46a-4d79-8219-7b8a5ec9de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAveragePooling(BaseLayer):\n",
    "    def __init__(self):\n",
    "        super().__init__(input_size=None, output_size=None, activation=None)\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.mean(X, axis=1)\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads=True):\n",
    "        seq_len = X.shape[1]\n",
    "        dinput = np.repeat(doutput[:, None, :] / seq_len, seq_len, axis=1)\n",
    "\n",
    "        return dinput, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043f074-3438-419a-a2d5-6c010cc6296d",
   "metadata": {},
   "source": [
    "### Graph layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40abe6ee-ce9f-4024-9659-c8c3fec8aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeGatedGraphConv(LayersBlock):\n",
    "    def __init__(\n",
    "            self, in_channels: int, out_channels: int, edge_dim: int,\n",
    "            message_hid_act: str = 'silu', update_hid_act: str = 'silu', gate_act: str = 'sigmoid',\n",
    "            residual: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.edge_dim = edge_dim\n",
    "        self.residual = residual\n",
    "\n",
    "        self.add_layers([\n",
    "            # Message layers\n",
    "            {\"message_in\": Dense(in_channels * 2 + edge_dim + 1, out_channels, activation=message_hid_act)},\n",
    "            {\"message_out\": Dense(out_channels, out_channels, activation='linear')},\n",
    "            # Gate\n",
    "            {\"gate\": Dense(out_channels, 1, activation=gate_act)},\n",
    "            # Update layers\n",
    "            {\"node_update_in\": Dense(in_channels + out_channels, out_channels, activation=update_hid_act)},\n",
    "            {\"node_update_out\": Dense(out_channels, in_channels if residual else out_channels, activation='linear')},\n",
    "            {\"edge_update_in\": Dense(self.edge_dim + out_channels, out_channels, activation=update_hid_act)},\n",
    "            {\"edge_update_out\": Dense(out_channels, self.edge_dim if residual else out_channels, activation='linear')},\n",
    "        ])\n",
    "        \n",
    "\n",
    "        self._edge_index_cache = None\n",
    "\n",
    "    def forward(self, X: Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray], *args, **kwargs) -> np.ndarray:\n",
    "        \"\"\"Forward pass of edge-gated graph convolution.\n",
    "        \n",
    "        Args:\n",
    "            x: Node features, shape [num_nodes, in_channels]\n",
    "            edge_attr: Edge features, shape [num_edges, edge_dim]\n",
    "            edge_dist: Edge distances, shape [num_edges]\n",
    "            edge_index: Edge indices, shape [2, num_edges]\n",
    "            \n",
    "        Returns:\n",
    "            Updated node features, shape [num_nodes, in_channels]\n",
    "            Updated edge features, shape [num_edges, edge_dim]\n",
    "        \"\"\"\n",
    "        X, edge_attr, edge_dist, edge_index = X\n",
    "        # params = ['edge_index', 'edge_attr', 'edge_dist']\n",
    "        # if kwargs:\n",
    "        #     for param in params:\n",
    "        #         if param not in kwargs\n",
    "        #             raise ValueError(f\"Argument is missing: {param}\")\n",
    "        #     edge_index, edge_attr, edge_dist = kwargs[\"edge_index\"], kwargs[\"edge_attr\"], kwargs[\"edge_dist\"]\n",
    "        # elif args:\n",
    "        #     if len(args) < 3:\n",
    "        #         raise ValueError(f\"Arguments should be given: {len(params)}, given only {len(args)}\")\n",
    "        #     edge_index, edge_attr, edge_dist = args[:3]\n",
    "        # else:\n",
    "        #     raise ValueError(f\"Forward required extra arguments: {params}\")\n",
    "\n",
    "        num_nodes = X.shape[0]\n",
    "        num_edges = edge_index.shape[1]\n",
    "\n",
    "        self._edge_index_cache = edge_index\n",
    "        # Gather source and destination node features\n",
    "        X_src = X[edge_index[0]]  # [num_edges, in_channels]\n",
    "        X_dst = X[edge_index[1]]  # [num_edges, in_channels]\n",
    "        \n",
    "        # Concatenate: [x_i, x_j, edge_attr, edge_dist]\n",
    "        message_input = np.concatenate([X_src, X_dst, edge_attr, edge_dist[:, np.newaxis]], axis=1)\n",
    "\n",
    "        # Forward message MLP\n",
    "        messages = self._forward_layer('message_in', message_input)\n",
    "        messages = self._forward_layer('message_out', messages)\n",
    "        # Get gate activation\n",
    "        gate = self._forward_layer('gate', messages)\n",
    "        gated_messages = messages * gate  # [num_edges, out_channels]\n",
    "\n",
    "        # Argregate by summing gated messages in dest nodes\n",
    "        aggregated = np.zeros((num_nodes, self.out_channels))\n",
    "        np.add.at(aggregated, edge_index[1], gated_messages) \n",
    "\n",
    "        # Update nodes\n",
    "        node_upd_input = np.concatenate([X, aggregated], axis=1)  # [num_nodes, in_channels + out_channels]\n",
    "        node_upd = self._forward_layer('node_update_in', node_upd_input)\n",
    "        node_upd = self._forward_layer('node_update_out', node_upd)\n",
    "        \n",
    "        edge_upd_input = np.concatenate([edge_attr, messages], axis=1)\n",
    "        edge_upd = self._forward_layer('edge_update_in', edge_upd_input)\n",
    "        edge_upd = self._forward_layer('edge_update_out', edge_upd)\n",
    "\n",
    "        # Updates\n",
    "        if self.residual:\n",
    "            X += node_upd\n",
    "            edge_attr += edge_upd\n",
    "            return X, edge_attr\n",
    "        else:\n",
    "            return node_upd, edge_upd\n",
    "\n",
    "    def backward(self, X, output, doutput: Tuple[np.ndarray, np.ndarray], calc_grads=True):\n",
    "        dnodes, dedges, dedge_dist = doutput\n",
    "\n",
    "        src_nodes = self._edge_index_cache[0]\n",
    "        dst_nodes = self._edge_index_cache[1]\n",
    "        dedge_upd = self._backward_layer('edge_update_out', dedges, calc_grads=calc_grads)\n",
    "        dedge_upd = self._backward_layer('edge_update_in', dedge_upd, calc_grads=calc_grads)\n",
    "        dedge_input, dmessages = dedge_upd[:, :self.edge_dim], dedge_upd[:, self.edge_dim:]\n",
    "        \n",
    "        dnode_upd = self._backward_layer('node_update_out', dnodes, calc_grads=calc_grads)\n",
    "        dnode_upd = self._backward_layer('node_update_in', dnode_upd, calc_grads=calc_grads)\n",
    "        dnode_input, dagg = dnode_upd[:, :self.in_channels], dnode_upd[:, self.in_channels:]        \n",
    "        \n",
    "        dgated_messages = dagg[dst_nodes]\n",
    "\n",
    "        gates_output = self._layers_outputs[self.layers_names.index('gate')]\n",
    "        messages_output = self._layers_outputs[self.layers_names.index('message_out')]\n",
    "\n",
    "        dmessages += dgated_messages * gates_output  # [num_edges, out_channels]\n",
    "        \n",
    "        dgate = np.sum(dgated_messages * messages_output, axis=1, keepdims=True)  # [num_edges, 1]\n",
    "        dgate = self._backward_layer('gate', dgate, calc_grads=calc_grads)\n",
    "        \n",
    "        dmessages += dgate\n",
    "        dmessages = self._backward_layer('message_out', dmessages, calc_grads=calc_grads)\n",
    "        dmessages = self._backward_layer('message_in', dmessages, calc_grads=calc_grads)\n",
    "\n",
    "        grad_x_src = dmessages[:, :self.in_channels]\n",
    "        grad_x_dst = dmessages[:, self.in_channels:2*self.in_channels]\n",
    "    \n",
    "        np.add.at(dnode_input, src_nodes, grad_x_src)\n",
    "        np.add.at(dnode_input, dst_nodes, grad_x_dst)\n",
    "\n",
    "        dedge_input += dmessages[:, -self.edge_dim-1:-1] \n",
    "        dedge_dist *= dmessages[:, -1]\n",
    "\n",
    "        if self.residual:\n",
    "            dnodes += dnode_input\n",
    "            dedges += dedge_input\n",
    "            return (dnodes, dedges, dedge_dist), self._layers_grads\n",
    "        else:\n",
    "            return (dnode_input, dedge_input, dedge_dist), self._layers_grads\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        super().clear_tmp()\n",
    "        self._edge_index_cache = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17335481-6674-458e-8cce-410169044b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAvgPooling(BaseLayer):\n",
    "    def __init__(self, input_size, dim: int = 1):\n",
    "        super().__init__(input_size, input_size, activation=None)\n",
    "        \n",
    "        self._n_nodes = None\n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 0\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        self._n_nodes = X.shape[0]\n",
    "        return np.mean(X, axis=0)[None, :]\n",
    "\n",
    "    def backward(self, X, output, doutput, calc_grads: bool = True, *args, **kwargs):\n",
    "        return np.repeat(doutput / self._n_nodes, self._n_nodes, axis=0), {}\n",
    "\n",
    "    def clear_tmp(self):\n",
    "        self._n_nodes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d1ed778-ef23-467a-b05b-e6419413f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALIGNNBlock(LayersBlock):\n",
    "    \"\"\"\n",
    "    Multi-layer EdgeGatedGraphConv block\n",
    "    \"\"\"\n",
    "    def __init__(self, block_size: int, input_dim: int, output_dims: Union[int, List[int]], edge_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(output_dims, int):\n",
    "            output_dims = [output_dims] * block_size\n",
    "        elif len(output_dims) > block_size:\n",
    "            output_dims = output_dims[:block_size]\n",
    "        elif len(output_dims) < block_size:\n",
    "            output_dims += [output_dims[-1]] * (block_size - len(output_dims))\n",
    "    \n",
    "        self.block_size = block_size\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dims = output_dims\n",
    "\n",
    "        self.edge_dims = [edge_dim]\n",
    "        for i in range(self.block_size):\n",
    "            if input_dim == self.output_dims[i]:\n",
    "                self.edge_dims.append(edge_dim)\n",
    "            else:\n",
    "                self.edge_dims += self.output_dims[i:-1]\n",
    "                break\n",
    "\n",
    "        for i in range(self.block_size):\n",
    "            if i == 0:\n",
    "                layer = EdgeGatedGraphConv(\n",
    "                    in_channels=input_dim,\n",
    "                    out_channels=self.output_dims[i],\n",
    "                    edge_dim=self.edge_dims[i],\n",
    "                    residual=input_dim == self.output_dims[i]\n",
    "                )\n",
    "            else:\n",
    "                layer = EdgeGatedGraphConv(\n",
    "                    in_channels=self.output_dims[i-1],\n",
    "                    out_channels=self.output_dims[i],\n",
    "                    edge_dim=self.edge_dims[i],\n",
    "                    residual=self.output_dims[i-1] == self.output_dims[i]\n",
    "                )\n",
    "            self.add_layer(layer, f\"eggc_{i}\")\n",
    "\n",
    "        self.add_layer(GraphAvgPooling(input_size=self.output_dims[-1]), \"pooling\")\n",
    "    \n",
    "    def _partial_forward(self, X: Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]):\n",
    "        node_feats, edge_attr, edge_dist, edge_index  = X\n",
    "        # Pass through each GCN layer\n",
    "        for i, layer_name in enumerate(self.layers_names[:-1]):\n",
    "            node_feats, edge_attr = self._forward_layer(layer_name, (node_feats, edge_attr, edge_dist, edge_index))\n",
    "\n",
    "        avg_feats = self._forward_layer(\"pooling\", node_feats)\n",
    "        return avg_feats\n",
    "\n",
    "    def forward(self, X: List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]], *args, **kwargs) -> np.ndarray:\n",
    "        \"\"\"Forward pass of edge-gated graph convolution.\n",
    "        \n",
    "        Args:\n",
    "            x: Node features, shape [num_nodes, in_channels]\n",
    "            edge_attr: Edge features, shape [num_edges, edge_dim]\n",
    "            edge_dist: Edge distances, shape [num_edges]\n",
    "            edge_index: Edge indices, shape [2, num_edges]\n",
    "            \n",
    "        Returns:\n",
    "            Updated node features, shape [num_nodes, output_dim]\n",
    "        \"\"\"\n",
    "        result = np.zeros((len(X), self.output_dims[-1]))\n",
    "        for i in range(len(X)):\n",
    "            result[i] = self._partial_forward(X[i])[0]\n",
    "    \n",
    "        # node_feats, edge_attr, edge_dist, edge_index  = X\n",
    "        # # Pass through each GCN layer\n",
    "        # for i, layer_name in enumerate(self.layers_names):\n",
    "        #     node_feats, edge_attr = self._forward_layer(layer_name, (node_feats, edge_attr, edge_dist, edge_index))\n",
    "        return result\n",
    "\n",
    "    def _partial_backward(self, X: Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray], doutput: np.ndarray, calc_grads: bool = True):\n",
    "        node_feats, edge_attr, edge_dist, edge_index  = X\n",
    "\n",
    "        dinput = self._backward_layer(\"pooling\", doutput, calc_grads)\n",
    "        dedge_attr = np.zeros((edge_attr.shape[0], self.edge_dims[-1]))\n",
    "        dedge_dist = np.zeros_like(edge_dist)\n",
    "\n",
    "        # Backward through layers in reverse order\n",
    "        for layer_name in self.layers_names[:-1][::-1]:\n",
    "            dinput, dedge_attr, dedge_dist = self._backward_layer(layer_name, (dinput, dedge_attr, dedge_dist), calc_grads)\n",
    "\n",
    "        return (dinput, dedge_attr, dedge_dist)\n",
    "    \n",
    "    def backward(self, X: List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]], output: np.ndarray, \n",
    "                 doutput: np.ndarray, calc_grads: bool = True) -> Tuple[Tuple[np.ndarray, np.ndarray], List]:\n",
    "        \"\"\"\n",
    "        Backward pass through GCN block\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "            output: Final output from forward pass\n",
    "            doutput: Gradient of loss w.r.t. output\n",
    "            calc_grads: Whether to calculate gradients\n",
    "        \n",
    "        Returns:\n",
    "            (dinput, dedge_attr, dedge_dist): Tuple of gradients w.r.t. inputs\n",
    "            grads: List of gradients for all layers\n",
    "        \"\"\"\n",
    "\n",
    "        results = []\n",
    "        for i in range(len(X)):\n",
    "            results.append(self._partial_backward(X[i], doutput[i:i+1], calc_grads))\n",
    "    \n",
    "        return results\n",
    "    \n",
    "        # node_feats, edge_attr, edge_dist, edge_index  = X\n",
    "\n",
    "        # dinput = doutput\n",
    "        # dedge_attr = np.zeros((edge_attr.shape[0], self.edge_dims[-1]))\n",
    "        # dedge_dist = np.zeros_like(edge_dist)\n",
    "\n",
    "        # # Backward through layers in reverse order\n",
    "        # for layer_name in self.layers_names[::-1]:\n",
    "        #     dinput, dedge_attr, dedge_dist = self._backward_layer(layer_name, (dinput, dedge_attr, dedge_dist), calc_grads)\n",
    "\n",
    "        # return (dinput, dedge_attr, dedge_dist), self._layers_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad11bd-8b4d-4391-a6d5-5f8068cc8633",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Other graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd4b6704-7965-43cd-9232-82c011a075d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvLayer(BaseLayer):\n",
    "    \"\"\"\n",
    "    Graph Convolutional Layer based on Kipf & Welling (ICLR 2017)\n",
    "    Implements: H' = σ(Ã·H·W + b) where Ã = D^(-1/2) A D^(-1/2)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, output_size: int, activation='linear', \n",
    "                 use_bias: bool = True, normalize: bool = True):\n",
    "        super().__init__(input_size, output_size, activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        # Cache for backward pass\n",
    "        self._A_norm = None  # Normalized adjacency matrix\n",
    "        self._AH = None      # A @ H product\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights using Glorot initialization\"\"\"\n",
    "        limit = np.sqrt(6.0 / (self.input_size + self.output_size))\n",
    "        self.weights = np.random.uniform(-limit, limit, \n",
    "                                         (self.input_size, self.output_size))\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = np.zeros((1, self.output_size))\n",
    "        else:\n",
    "            self.bias = None\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Return number of trainable parameters\"\"\"\n",
    "        params = self.weights.size\n",
    "        if self.use_bias:\n",
    "            params += self.bias.size\n",
    "        return params\n",
    "    \n",
    "    def _normalize_adjacency(self, A: np.ndarray, add_self_loops: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Normalize adjacency matrix: D^(-1/2) A D^(-1/2)\n",
    "        \n",
    "        Args:\n",
    "            A: Adjacency matrix (n_nodes, n_nodes)\n",
    "            add_self_loops: Whether to add self-connections\n",
    "        \n",
    "        Returns:\n",
    "            Normalized adjacency matrix\n",
    "        \"\"\"\n",
    "        n_nodes = A.shape[0]\n",
    "        \n",
    "        if add_self_loops:\n",
    "            A = A + np.eye(n_nodes)\n",
    "        \n",
    "        # Compute degree matrix\n",
    "        D = np.diag(np.sum(A, axis=1))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D) + 1e-10))\n",
    "        \n",
    "        # Normalize: D^(-1/2) A D^(-1/2)\n",
    "        A_norm = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "        \n",
    "        return A_norm\n",
    "    \n",
    "    def forward(self, X: Tuple[np.ndarray, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass for GCN layer\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "               node_features: (n_nodes, input_dim)\n",
    "               adjacency_matrix: (n_nodes, n_nodes)\n",
    "        \n",
    "        Returns:\n",
    "            Updated node features: (n_nodes, output_dim)\n",
    "        \"\"\"\n",
    "        H, A = X  # Unpack node features and adjacency matrix\n",
    "        \n",
    "        # Cache for backward pass\n",
    "        \n",
    "        # Normalize adjacency matrix if required\n",
    "        if self.normalize:\n",
    "            A_norm = self._normalize_adjacency(A)\n",
    "        else:\n",
    "            A_norm = A\n",
    "        \n",
    "        # Cache normalized adjacency for backward\n",
    "        self._A_norm = A_norm\n",
    "        \n",
    "        # Graph convolution: A_norm @ H @ W\n",
    "        self._AH = A_norm @ H  # Cache for backward\n",
    "        Z = self._AH @ self.weights\n",
    "        \n",
    "        # Add bias if enabled\n",
    "        if self.use_bias:\n",
    "            Z += self.bias\n",
    "        \n",
    "        # Apply activation\n",
    "        output = self.activation(Z)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, X: Tuple[np.ndarray, np.ndarray], output: np.ndarray, \n",
    "                 doutput: np.ndarray, calc_grads: bool = True) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple]:\n",
    "        \"\"\"\n",
    "        Backward pass for GCN layer\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "            output: Layer output from forward pass\n",
    "            doutput: Gradient of loss w.r.t. output\n",
    "            calc_grads: Whether to calculate gradients\n",
    "        \n",
    "        Returns:\n",
    "            dinput: Tuple of gradients w.r.t. inputs (dH, dA)\n",
    "            grads: Tuple of gradients for weights (dW, db)\n",
    "        \"\"\"\n",
    "        H = X\n",
    "        n_nodes = H.shape[0]\n",
    "        \n",
    "        # Gradient through activation\n",
    "        dZ = doutput * self.activation.derivative(output)\n",
    "        \n",
    "        # Initialize gradients\n",
    "        dW = np.zeros_like(self.weights)\n",
    "        db = np.zeros_like(self.bias) if self.use_bias else None\n",
    "        dH = np.zeros_like(X)\n",
    "        dA = np.zeros_like(self._A_norm) if calc_grads else None\n",
    "        \n",
    "        if calc_grads:\n",
    "            # Gradient w.r.t. weights: dL/dW = (A_norm @ H)^T @ dZ\n",
    "            dW = self._AH.T @ dZ\n",
    "            \n",
    "            # Gradient w.r.t. bias: dL/db = sum(dZ, axis=0)\n",
    "            if self.use_bias:\n",
    "                db = np.sum(dZ, axis=0, keepdims=True)\n",
    "            \n",
    "            # Gradient w.r.t. H: dL/dH = A_norm^T @ dZ @ W^T\n",
    "            dH = self._A_norm.T @ (dZ @ self.weights.T)\n",
    "            \n",
    "            # Gradient w.r.t. A (if needed for higher-order layers)\n",
    "            if self.normalize:\n",
    "                # For normalized adjacency, we need to compute gradient through normalization\n",
    "                # This is simplified - in practice, you might want to compute full gradient\n",
    "                dA_temp = np.zeros_like(self._A_norm)\n",
    "                # Basic gradient through adjacency (simplified)\n",
    "                # In practice, you'd need to compute gradient through normalization\n",
    "                dA = dA_temp\n",
    "            else:\n",
    "                # For unnormalized adjacency: dL/dA = dZ @ W^T @ H^T\n",
    "                dA = dZ @ self.weights.T @ H.T\n",
    "                # Symmetrize since adjacency should be symmetric\n",
    "                dA = 0.5 * (dA + dA.T)\n",
    "        \n",
    "        # Clear cache if not training\n",
    "        if not self.training:\n",
    "            self.clear_tmp()\n",
    "        \n",
    "        return (dH, dA), (dW, db)\n",
    "    \n",
    "    def clear_tmp(self):\n",
    "        \"\"\"Clear cached temporary variables\"\"\"\n",
    "        self._A_norm = None\n",
    "        self._AH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "577ca204-2263-4e27-a588-3676066bf685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionLayer(BaseLayer):\n",
    "    \"\"\"\n",
    "    Graph Attention Layer (GAT) based on Velickovic et al. (ICLR 2018)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, output_size: int, n_heads: int = 1, \n",
    "                 dropout: float = 0.0, concat: bool = True, activation='elu'):\n",
    "        super().__init__(input_size * n_heads if concat else output_size, \n",
    "                        output_size, activation)\n",
    "        self.n_heads = n_heads\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Attention mechanism parameters\n",
    "        self.W = None  # Linear transformation weights\n",
    "        self.a = None  # Attention parameters\n",
    "        \n",
    "        # Cache for backward\n",
    "        self._H = None\n",
    "        self._attention = None\n",
    "        self._neighbors = None\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights for GAT layer\"\"\"\n",
    "        # Linear transformation weights per head\n",
    "        self.W = np.random.randn(self.n_heads, self.input_size, self.output_size) * 0.01\n",
    "        \n",
    "        # Attention parameters: [a_left, a_right] for each head\n",
    "        self.a = np.random.randn(self.n_heads, 2 * self.output_size) * 0.01\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = np.zeros((1, self.output_size * self.n_heads if self.concat else self.output_size))\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        \"\"\"Return number of trainable parameters\"\"\"\n",
    "        params = self.W.size + self.a.size\n",
    "        if self.use_bias:\n",
    "            params += self.bias.size\n",
    "        return params\n",
    "    \n",
    "    def _prepare_attention_inputs(self, H: np.ndarray, A: np.ndarray):\n",
    "        \"\"\"Prepare inputs for attention computation\"\"\"\n",
    "        n_nodes = H.shape[0]\n",
    "        \n",
    "        # Apply linear transformation per head\n",
    "        H_transformed = np.stack([H @ self.W[h] for h in range(self.n_heads)], axis=0)\n",
    "        \n",
    "        # Find neighbors for each node\n",
    "        neighbors = [np.where(A[i] > 0)[0] for i in range(n_nodes)]\n",
    "        \n",
    "        return H_transformed, neighbors\n",
    "    \n",
    "    def _compute_attention(self, H_transformed: np.ndarray, neighbors: List[np.ndarray], \n",
    "                          i: int, h: int) -> np.ndarray:\n",
    "        \"\"\"Compute attention scores for node i in head h\"\"\"\n",
    "        n_nodes = H_transformed.shape[1]\n",
    "        \n",
    "        # Get transformed features for node i and its neighbors\n",
    "        hi = H_transformed[h, i]  # (output_size,)\n",
    "        neighbors_i = neighbors[i]\n",
    "        \n",
    "        if len(neighbors_i) == 0:\n",
    "            return np.zeros(n_nodes)\n",
    "        \n",
    "        # Concatenate hi with all hj\n",
    "        hi_repeated = np.tile(hi, (len(neighbors_i), 1))  # (n_neighbors, output_size)\n",
    "        hj = H_transformed[h, neighbors_i]  # (n_neighbors, output_size)\n",
    "        \n",
    "        # Compute attention scores: a^T [Wh_i || Wh_j]\n",
    "        concat = np.concatenate([hi_repeated, hj], axis=1)  # (n_neighbors, 2*output_size)\n",
    "        scores = concat @ self.a[h]  # (n_neighbors,)\n",
    "        \n",
    "        # Apply LeakyReLU\n",
    "        scores = np.maximum(0.01 * scores, scores)\n",
    "        \n",
    "        # Create attention vector for all nodes\n",
    "        attention = np.zeros(n_nodes)\n",
    "        attention[neighbors_i] = scores\n",
    "        \n",
    "        # Softmax over neighbors\n",
    "        mask = (attention != 0).astype(float)\n",
    "        exp_attention = np.exp(attention) * mask\n",
    "        sum_exp = np.sum(exp_attention) + 1e-10\n",
    "        attention = exp_attention / sum_exp\n",
    "        \n",
    "        return attention\n",
    "    \n",
    "    def forward(self, X: Tuple[np.ndarray, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass for GAT layer\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "        \n",
    "        Returns:\n",
    "            Updated node features\n",
    "        \"\"\"\n",
    "        H, A = X\n",
    "        n_nodes = H.shape[0]\n",
    "        \n",
    "        # Cache for backward\n",
    "        self._H = H\n",
    "        \n",
    "        # Prepare inputs\n",
    "        H_transformed, neighbors = self._prepare_attention_inputs(H, A)\n",
    "        self._neighbors = neighbors\n",
    "        \n",
    "        # Compute attention for all nodes and heads\n",
    "        attention_matrices = []\n",
    "        for h in range(self.n_heads):\n",
    "            attention_h = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                attention_h[i] = self._compute_attention(H_transformed, neighbors, i, h)\n",
    "            attention_matrices.append(attention_h)\n",
    "        \n",
    "        self._attention = np.stack(attention_matrices, axis=0)  # (n_heads, n_nodes, n_nodes)\n",
    "        \n",
    "        # Apply attention and aggregate\n",
    "        outputs = []\n",
    "        for h in range(self.n_heads):\n",
    "            # Attention-weighted sum: ∑ α_ij * Wh_j\n",
    "            output_h = self._attention[h] @ H_transformed[h]  # (n_nodes, output_size)\n",
    "            outputs.append(output_h)\n",
    "        \n",
    "        # Concatenate or average heads\n",
    "        if self.concat:\n",
    "            output = np.concatenate(outputs, axis=1)  # (n_nodes, n_heads * output_size)\n",
    "        else:\n",
    "            output = np.mean(outputs, axis=0)  # (n_nodes, output_size)\n",
    "        \n",
    "        # Add bias\n",
    "        if self.use_bias:\n",
    "            output += self.bias\n",
    "        \n",
    "        # Apply activation\n",
    "        output = self.activation(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, X: Tuple[np.ndarray, np.ndarray], output: np.ndarray, \n",
    "                 doutput: np.ndarray, calc_grads: bool = True) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple]:\n",
    "        \"\"\"\n",
    "        Backward pass for GAT layer (simplified - full implementation is complex)\n",
    "        \"\"\"\n",
    "        H, A = X\n",
    "        \n",
    "        # Gradient through activation\n",
    "        dZ = doutput * self.activation.derivative(output)\n",
    "        \n",
    "        # Simplified gradient computation\n",
    "        # Note: Full GAT backward is complex due to attention mechanism\n",
    "        \n",
    "        if calc_grads:\n",
    "            # Approximate gradients (simplified)\n",
    "            dW = [np.zeros_like(self.W[h]) for h in range(self.n_heads)]\n",
    "            da = [np.zeros_like(self.a[h]) for h in range(self.n_heads)]\n",
    "            \n",
    "            # For each head\n",
    "            for h in range(self.n_heads):\n",
    "                # Gradient w.r.t. W (simplified)\n",
    "                if self.concat:\n",
    "                    dZ_h = dZ[:, h*self.output_size:(h+1)*self.output_size]\n",
    "                else:\n",
    "                    dZ_h = dZ / self.n_heads\n",
    "                \n",
    "                # Approximate: dW ≈ H^T @ dZ_h\n",
    "                dW[h] = H.T @ dZ_h\n",
    "                \n",
    "                # Gradient w.r.t. a (very simplified)\n",
    "                da[h] = np.random.randn(*self.a[h].shape) * 0.01\n",
    "            \n",
    "            dW = np.stack(dW, axis=0)\n",
    "            da = np.stack(da, axis=0)\n",
    "            \n",
    "            # Gradient w.r.t. H (simplified)\n",
    "            dH = np.zeros_like(H)\n",
    "            for h in range(self.n_heads):\n",
    "                if self.concat:\n",
    "                    dZ_h = dZ[:, h*self.output_size:(h+1)*self.output_size]\n",
    "                else:\n",
    "                    dZ_h = dZ / self.n_heads\n",
    "                \n",
    "                # Approximate: dH ≈ A @ dZ_h @ W^T\n",
    "                dH += A @ dZ_h @ self.W[h].T\n",
    "            \n",
    "            # Gradient w.r.t. bias\n",
    "            if self.use_bias:\n",
    "                db = np.sum(dZ, axis=0, keepdims=True)\n",
    "            else:\n",
    "                db = None\n",
    "            \n",
    "            grads = (dW, da, db)\n",
    "        else:\n",
    "            dH = np.zeros_like(H)\n",
    "            grads = (None, None, None)\n",
    "        \n",
    "        # Gradient w.r.t. A (not typically trained)\n",
    "        dA = np.zeros_like(A)\n",
    "        \n",
    "        if not self.training:\n",
    "            self.clear_tmp()\n",
    "        \n",
    "        return (dH, dA), grads\n",
    "    \n",
    "    def clear_tmp(self):\n",
    "        \"\"\"Clear cached temporary variables\"\"\"\n",
    "        self._H = None\n",
    "        self._attention = None\n",
    "        self._neighbors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a776e7c-4496-42f9-8c65-fa084104670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNBlock(LayersBlock):\n",
    "    \"\"\"\n",
    "    Multi-layer GCN block\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], output_dim: int, activations: List[str] = None, normalize: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Create GCN layers\n",
    "        dims = [input_dim] + hidden_dims + [output_dim]\n",
    "        \n",
    "        if activations is None:\n",
    "            activations = ['silu'] * (len(dims) - 2) + ['linear']\n",
    "        \n",
    "        for i in range(len(dims) - 1):\n",
    "            layer = GraphConvLayer(\n",
    "                input_size=dims[i],\n",
    "                output_size=dims[i + 1],\n",
    "                activation=activations[i] if i < len(activations) else 'linear',\n",
    "                normalize=normalize\n",
    "            )\n",
    "            self.add_layer(layer, f\"gcn_{i}\")\n",
    "    \n",
    "    def forward(self, X: Tuple[np.ndarray, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass through GCN block\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "        \n",
    "        Returns:\n",
    "            Updated node features\n",
    "        \"\"\"\n",
    "        H, A = X\n",
    "        output = H\n",
    "        \n",
    "        # Pass through each GCN layer\n",
    "        for i, layer_name in enumerate(self.layers_names):\n",
    "            output = self._forward_layer(layer_name, (output, A))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, X: Tuple[np.ndarray, np.ndarray], output: np.ndarray, \n",
    "                 doutput: np.ndarray, calc_grads: bool = True) -> Tuple[Tuple[np.ndarray, np.ndarray], List]:\n",
    "        \"\"\"\n",
    "        Backward pass through GCN block\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "            output: Final output from forward pass\n",
    "            doutput: Gradient of loss w.r.t. output\n",
    "            calc_grads: Whether to calculate gradients\n",
    "        \n",
    "        Returns:\n",
    "            dinput: Tuple of gradients w.r.t. inputs\n",
    "            all_grads: List of gradients for all layers\n",
    "        \"\"\"\n",
    "        H, A = X\n",
    "        \n",
    "        # Initialize gradients\n",
    "        dcurrent = doutput\n",
    "        all_grads = []\n",
    "        \n",
    "        # Backward through layers in reverse order\n",
    "        for i in range(len(self.layers) - 1, -1, -1):\n",
    "            layer_name = self.layers_names[i]\n",
    "                    \n",
    "            # Backward through layer\n",
    "            dinput = self._backward_layer(layer_name, dcurrent, calc_grads)\n",
    "            \n",
    "            # Handle residual connection gradient\n",
    "            if self.residual and i > 0 and i < len(self.layers) - 1:\n",
    "                # Add gradient from residual connection\n",
    "                dcurrent_H, dA = dinput\n",
    "                dcurrent_H += dcurrent  # Gradient through residual\n",
    "                dinput = (dcurrent_H, dA)\n",
    "            \n",
    "            dcurrent = dinput[0]  # dH for next layer\n",
    "            all_grads.append(grads)\n",
    "        \n",
    "        # Reverse gradients list to match layer order\n",
    "        all_grads.reverse()\n",
    "        \n",
    "        return dinput, self._layers_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16411ad3-88a8-44cc-9b19-d52a51746b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPoolingLayer(BaseLayer):\n",
    "    \"\"\"\n",
    "    Graph pooling layer using top-k pooling\n",
    "    \"\"\"\n",
    "    def __init__(self, ratio: float = 0.5, activation='sigmoid'):\n",
    "        super().__init__(input_size=None, output_size=None, activation=activation)\n",
    "        self.ratio = ratio\n",
    "        \n",
    "        # Cache for backward\n",
    "        self._scores = None\n",
    "        self._indices = None\n",
    "        self._A = None\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"No trainable parameters for pooling\"\"\"\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return 0\n",
    "    \n",
    "    def forward(self, X: Tuple[np.ndarray, np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Forward pass for pooling layer\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (pooled_features, pooled_adjacency)\n",
    "        \"\"\"\n",
    "        H, A = X\n",
    "        n_nodes = H.shape[0]\n",
    "        \n",
    "        # Cache for backward\n",
    "        self._A = A\n",
    "        \n",
    "        # Learn node scores (simplified - could be learned)\n",
    "        scores = H.mean(axis=1)  # Simple scoring based on feature mean\n",
    "        scores = self.activation(scores.reshape(-1, 1))\n",
    "        self._scores = scores.flatten()\n",
    "        \n",
    "        # Select top-k nodes\n",
    "        k = max(1, int(n_nodes * self.ratio))\n",
    "        indices = np.argsort(-self._scores)[:k]\n",
    "        self._indices = indices\n",
    "        \n",
    "        # Pool features\n",
    "        H_pooled = H[indices] * self._scores[indices, np.newaxis]\n",
    "        \n",
    "        # Pool adjacency matrix\n",
    "        A_pooled = A[np.ix_(indices, indices)]\n",
    "        \n",
    "        return H_pooled, A_pooled\n",
    "    \n",
    "    def backward(self, X: Tuple[np.ndarray, np.ndarray], output: Tuple[np.ndarray, np.ndarray], \n",
    "                 doutput: Tuple[np.ndarray, np.ndarray], calc_grads: bool = True) -> Tuple:\n",
    "        \"\"\"\n",
    "        Backward pass for pooling layer\n",
    "        \"\"\"\n",
    "        H, A = X\n",
    "        dH_pooled, dA_pooled = doutput\n",
    "        indices = self._indices\n",
    "        \n",
    "        # Initialize gradients\n",
    "        dH = np.zeros_like(H)\n",
    "        dA = np.zeros_like(A)\n",
    "        \n",
    "        # Gradient w.r.t. features\n",
    "        dH[indices] = dH_pooled * self._scores[indices, np.newaxis]\n",
    "        \n",
    "        # Gradient through scoring (simplified)\n",
    "        if calc_grads:\n",
    "            d_scores = np.zeros_like(self._scores)\n",
    "            d_scores[indices] = np.sum(dH_pooled * H[indices], axis=1)\n",
    "            # Additional gradient through activation\n",
    "            d_scores *= self.activation.derivative(self._scores)\n",
    "            # Distribute gradient to features (simplified)\n",
    "            dH += d_scores[:, np.newaxis] / H.shape[1]\n",
    "        \n",
    "        # Gradient w.r.t. adjacency\n",
    "        dA[np.ix_(indices, indices)] = dA_pooled\n",
    "        \n",
    "        if not self.training:\n",
    "            self.clear_tmp()\n",
    "        \n",
    "        return (dH, dA), ()\n",
    "    \n",
    "    def clear_tmp(self):\n",
    "        \"\"\"Clear cached temporary variables\"\"\"\n",
    "        self._scores = None\n",
    "        self._indices = None\n",
    "        self._A = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce486757-ec91-4a0b-a429-1536f311e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage function for regression\n",
    "class GCNRegressor(LayersBlock):\n",
    "    \"\"\"\n",
    "    Complete GCN model for regression tasks\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], output_dim: int = 1,\n",
    "                 n_gcn_layers: int = 2, dropout: float = 0.0, residual: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Add GCN layers\n",
    "        gcn_block = GCNBlock(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=hidden_dims,\n",
    "            output_dim=hidden_dims[-1] if hidden_dims else input_dim,\n",
    "            activations=['relu'] * n_gcn_layers,\n",
    "            residual=residual,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.add_layer(gcn_block, \"gcn_block\")\n",
    "        \n",
    "        # Add global pooling (for graph-level regression)\n",
    "        self.add_layer(GraphPoolingLayer(ratio=0.5), \"pooling\")\n",
    "        \n",
    "        # Add readout layers (you can use your existing Dense layers here)\n",
    "        # Example: self.add_layer(DenseLayer(...), \"readout\")\n",
    "    \n",
    "    def forward(self, X: Tuple[np.ndarray, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass for regression\n",
    "        \n",
    "        Args:\n",
    "            X: Tuple of (node_features, adjacency_matrix)\n",
    "        \n",
    "        Returns:\n",
    "            Regression predictions\n",
    "        \"\"\"\n",
    "        # Pass through GCN\n",
    "        gcn_output = self._forward_layer(\"gcn_block\", X)\n",
    "        \n",
    "        # Pool to graph-level representation\n",
    "        pooled_features, _ = self._forward_layer(\"pooling\", (gcn_output, X[1]))\n",
    "        \n",
    "        # Global mean pooling\n",
    "        graph_embedding = pooled_features.mean(axis=0, keepdims=True)\n",
    "        \n",
    "        # Pass through readout layers (using your existing dense layers)\n",
    "        # output = self._forward_layer(\"readout\", graph_embedding)\n",
    "        \n",
    "        return graph_embedding  # Replace with actual readout\n",
    "    \n",
    "    def backward(self, X: Tuple[np.ndarray, np.ndarray], output: np.ndarray, \n",
    "                 doutput: np.ndarray, calc_grads: bool = True) -> Tuple:\n",
    "        \"\"\"\n",
    "        Backward pass for regression\n",
    "        \"\"\"\n",
    "        # Backward through readout (if exists)\n",
    "        # dcurrent = self._backward_layer(\"readout\", doutput, calc_grads)\n",
    "        \n",
    "        # Backward through pooling\n",
    "        dcurrent = self._backward_layer(\"pooling\", doutput, calc_grads)\n",
    "        \n",
    "        # Backward through GCN\n",
    "        dinput, grads = self._backward_layer(\"gcn_block\", dcurrent, calc_grads)\n",
    "        \n",
    "        return dinput, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bbece-62b9-4f85-b8bc-30ccf0fb085e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aafe564-0fe7-4dfe-badb-6c898e095ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseOptimizer:\n",
    "    NAME = None\n",
    "    def __init__(self):\n",
    "        self.pending_grads = []\n",
    "\n",
    "    def add_gradients(self, layer: Union[BaseLayer, LayersBlock], grads: Union[Dict[str, np.array], List[Tuple[BaseLayer, Dict[str, np.array]]]]):\n",
    "        if isinstance(layer, LayersBlock) and isinstance(grads, list):\n",
    "            for grad in grads:\n",
    "                self.add_gradients(*grad)            \n",
    "        else:\n",
    "            self.pending_grads.append((layer, grads))\n",
    "    \n",
    "    def apply_gradients(self):\n",
    "        while self.pending_grads:\n",
    "            layer, grads = self.pending_grads.pop()\n",
    "            for _weights_name, _weights_grad in grads.items():\n",
    "                weights = getattr(layer, _weights_name, None)\n",
    "                if weights is None:\n",
    "                    continue\n",
    "                setattr(\n",
    "                    layer, _weights_name, \n",
    "                    self._grad_step(\"_\".join([layer.name, _weights_name]), weights, _weights_grad)\n",
    "                )\n",
    "\n",
    "    def _grad_step(self, layer_name: str, weights, grads):\n",
    "        raise NotImplementedError(\"Applying gradients not impelemted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a94098-0ff0-4e21-b5fa-c3949166e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleOptimizer(BaseOptimizer):\n",
    "    NAME = \"simple\"\n",
    "\n",
    "    def __init__(self, learning_rate: float = 1e-4):\n",
    "        super().__init__()\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def _grad_step(self, layer_name: str, weights, grads):\n",
    "        return weights - self.lr * grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f21fd4b-060a-4d71-9f95-3e934f9aadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumOptimizer(BaseOptimizer):\n",
    "    NAME = \"momentum\"\n",
    "\n",
    "    def __init__(self, learning_rate: float = 1e-4, momentum_betta: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.lr = learning_rate\n",
    "        self.betta = momentum_betta\n",
    "        self.prev_grads = {}\n",
    "\n",
    "    def _grad_step(self, layer_name: str, weights, grads):\n",
    "        if layer_name in self.prev_grads:\n",
    "            self.prev_grads[layer_name] = self.prev_grads[layer_name] * self.betta + self.lr * (1 - self.betta) * grads\n",
    "        else:\n",
    "            self.prev_grads[layer_name] = self.lr * grads\n",
    "        return weights - self.prev_grads[layer_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ae6220f-b345-42ff-abfa-7197019eed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer(BaseOptimizer):\n",
    "    NAME = \"adam\"\n",
    "\n",
    "    def __init__(self, learning_rate: float = 0.001, beta1: float = 0.9, \n",
    "                 beta2: float = 0.999, epsilon: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Adam optimizer implementation\n",
    "        \n",
    "        Args:\n",
    "            learning_rate: Step size\n",
    "            beta1: Exponential decay rate for first moment estimates\n",
    "            beta2: Exponential decay rate for second moment estimates  \n",
    "            epsilon: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # State dictionaries\n",
    "        self.m = {}  # First moment vector\n",
    "        self.v = {}  # Second moment vector\n",
    "        self.t = {}  # Time step counter per parameter tensor\n",
    "        \n",
    "    def _grad_step(self, layer_name: str, weights, grads):\n",
    "        \"\"\"\n",
    "        Apply Adam update rule\n",
    "        \"\"\"\n",
    "        # Initialize state for this parameter tensor if first time\n",
    "        if layer_name not in self.m:\n",
    "            self.m[layer_name] = np.zeros_like(weights)\n",
    "            self.v[layer_name] = np.zeros_like(weights)\n",
    "            self.t[layer_name] = 0\n",
    "        \n",
    "        # Update time step\n",
    "        self.t[layer_name] += 1\n",
    "        t = self.t[layer_name]\n",
    "        # Update biased first moment estimate\n",
    "        self.m[layer_name] = self.beta1 * self.m[layer_name] + (1 - self.beta1) * grads\n",
    "        # Update biased second raw moment estimate\n",
    "        self.v[layer_name] = self.beta2 * self.v[layer_name] + (1 - self.beta2) * (grads ** 2)\n",
    "        # Compute bias-corrected first moment estimate\n",
    "        m_hat = self.m[layer_name] / (1 - self.beta1 ** t)\n",
    "        # Compute bias-corrected second raw moment estimate\n",
    "        v_hat = self.v[layer_name] / (1 - self.beta2 ** t)\n",
    "        \n",
    "        # Update parameters\n",
    "        weights_updated = weights - self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        return weights_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66863f4b-4ce2-44f6-beac-3f26afed60f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple': <class '__main__.SimpleOptimizer'>, 'momentum': <class '__main__.MomentumOptimizer'>, 'adam': <class '__main__.AdamOptimizer'>}\n"
     ]
    }
   ],
   "source": [
    "# Find all classes based on Activation class\n",
    "OPTIMIZERS = {\n",
    "    v.NAME: v \n",
    "    for v in globals().values() \n",
    "    if isinstance(v, type) and BaseOptimizer in v.__bases__\n",
    "}\n",
    "\n",
    "print(OPTIMIZERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccbf1c-8990-4a2b-a7e5-507e308a1b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc45417b-1d8e-4c3d-9a8d-fe202c97f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLoss:\n",
    "    NAME = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "        self.val_history = []\n",
    "        self.epoch_loss = None\n",
    "        self.epoch_batch_cnt = 0\n",
    "\n",
    "    def calc(self, y_true, y_pred, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Loss calc not impelemted\")\n",
    "\n",
    "    def derivative(self, y_true, y_pred, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Loss derivative not impelemted\")\n",
    "\n",
    "    def batch_loss(self):\n",
    "        if self.epoch_loss is not None and self.epoch_batch_cnt > 0:\n",
    "            return self.epoch_loss / self.epoch_batch_cnt\n",
    "        return None\n",
    "\n",
    "    def _update_history(self):\n",
    "        batch_loss = self.batch_loss()\n",
    "        if batch_loss is not None:\n",
    "            self.history.append(batch_loss)\n",
    "\n",
    "    def start_epoch(self):\n",
    "        self._update_history()\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_batch_cnt = 0\n",
    "\n",
    "    def update_epoch(self, y_true, y_pred, *args, **kwargs):\n",
    "        self.epoch_loss += self.calc(y_true, y_pred, *args, **kwargs)\n",
    "        self.epoch_batch_cnt += 1\n",
    "        return self.batch_loss()\n",
    "\n",
    "    def end_epoch(self):\n",
    "        self._update_history()\n",
    "        self.epoch_loss = None\n",
    "        self.epoch_batch_cnt = 0\n",
    "\n",
    "    def val_loss(self, y_true, y_pred, *args, **kwargs):\n",
    "        loss = self.calc(y_true, y_pred, *args, **kwargs)\n",
    "        self.val_history.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.calc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d42cbbd7-d9ef-49c9-8584-072d2fbc5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(BaseLoss):\n",
    "    NAME = 'mse'\n",
    "\n",
    "    def calc(self, y_true, y_pred, *args, **kwargs):\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def derivative(self, y_true, y_pred, *args, **kwargs):\n",
    "        return 2 * (y_pred - y_true) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccaae49d-1dcf-42cf-a321-d04eb8c22aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE(BaseLoss):\n",
    "    NAME = 'mae'\n",
    "\n",
    "    def calc(self, y_true, y_pred, *args, **kwargs):\n",
    "        return np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "    def derivative(self, y_true, y_pred, *args, **kwargs):\n",
    "        return 2 * (y_pred - y_true) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8628b62-eca9-4fc0-bed5-1d60f6af1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWT(BaseLoss):\n",
    "    NAME = 'ewt'\n",
    "\n",
    "    def __init__(self, epsilon: float = 0.02):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def calc(self, y_true, y_pred, *args, **kwargs):\n",
    "        return (np.abs(y_pred - y_true) < self.epsilon).astype(np.int32).mean()\n",
    "\n",
    "    def derivative(self, y_true, y_pred, *args, **kwargs):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2868f330-6e4d-4f22-951d-713f995c21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropy(BaseLoss):\n",
    "    NAME = 'softmax_cross_entropy'\n",
    "\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.reduction = reduction\n",
    "        self.softmax = StableSoftmax()\n",
    "\n",
    "    def _one_hot(self, y_true, num_classes: int):\n",
    "        if y_true.ndim == 1 or (y_true.ndim == 2 and y_true.shape[1] == 1):\n",
    "            y_true_one_hot = np.eye(num_classes)[y_true.astype(int).flatten()]\n",
    "        else:\n",
    "            y_true_one_hot = y_true\n",
    "        return y_true_one_hot\n",
    "\n",
    "    def calc(self, y_true, y_pred, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward pass with logits (before softmax)\n",
    "        Args:\n",
    "            y_pred: Logits (before softmax) of shape (batch_size, num_classes)\n",
    "            y_true: True labels\n",
    "        \"\"\"        \n",
    "        # Apply softmax\n",
    "        y_pred = self.softmax(y_pred)\n",
    "        y_true_one_hot = self._one_hot(y_true, num_classes=y_pred.shape[1])\n",
    "   \n",
    "        # Compute cross entropy loss\n",
    "        losses = -np.sum(y_true_one_hot * np.log(y_pred + 1e-8), axis=1)\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return np.mean(losses)\n",
    "        elif self.reduction == 'sum':\n",
    "            return np.sum(losses)\n",
    "        else:\n",
    "            return losses\n",
    "    \n",
    "    def derivative(self, y_true, y_pred, *args, **kwargs):\n",
    "        \"\"\"Backward pass - more numerically stable\"\"\"\n",
    "        # Convert labels to one-hot\n",
    "        y_true_one_hot = self._one_hot(y_true, num_classes=y_pred.shape[1])\n",
    "        y_pred = self.softmax(y_pred)\n",
    "        \n",
    "        # Gradient: dL/dlogits = y_pred - y_true\n",
    "        batch_size = y_pred.shape[0]\n",
    "        doutput = (y_pred - y_true_one_hot) / batch_size\n",
    "\n",
    "        return doutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75ab5867-53e6-4fd4-a67b-e952c373aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDiv(BaseLoss):\n",
    "    NAME = 'kl_div'\n",
    "\n",
    "    def calc(self, mean, logvar, *args, **kwargs):\n",
    "        KLD = np.mean(\n",
    "            0.5 * np.sum(mean**2 + np.exp(logvar) - 1 - logvar, axis=1)\n",
    "        )         \n",
    "        return KLD\n",
    "\n",
    "    def derivative(self, mean, logvar, *args, **kwargs):\n",
    "        # dKLD/mean = sum_i( sum_j(mean[i][j]) / batch_size\n",
    "        # dKLD/logvar = 1/2 * sum_i( sum_j(e^(logvar[i][j]) - 1)) / batch_size\n",
    "        d_mean = mean / mean.shape[0]\n",
    "        d_logvar = 0.5 * (np.exp(logvar) - 1) / logvar.shape[0]\n",
    "        d_concat = np.concatenate([d_mean, d_logvar], axis=1)\n",
    "        return d_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8b5589e-f2fd-4028-986f-f0381c483a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': <class '__main__.MSE'>, 'mae': <class '__main__.MAE'>, 'ewt': <class '__main__.EWT'>, 'softmax_cross_entropy': <class '__main__.SoftmaxCrossEntropy'>, 'kl_div': <class '__main__.KLDiv'>}\n"
     ]
    }
   ],
   "source": [
    "# Find all classes based on Activation class\n",
    "LOSSES = {\n",
    "    v.NAME: v \n",
    "    for v in globals().values() \n",
    "    if isinstance(v, type) and BaseLoss in v.__bases__\n",
    "}\n",
    "\n",
    "print(LOSSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb485977-bc02-4ac9-8e56-113e62b34e7c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22685599-b2aa-4b29-86ad-fd29c950a4b8",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29c720a6-70cc-4e05-9c04-4bc0a4fe47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: Optional[List[BaseLayer]] = None):\n",
    "        self.layers = layers or []\n",
    "\n",
    "        self.epoch = None\n",
    "        self.verbose = 1\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.layers_times = {\n",
    "            \"forward\": {},\n",
    "            \"backward\": {}\n",
    "        }\n",
    "        self._clear_batch()\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def compile(self, loss='mse', optimizer='simple', extra_losses=[]):            \n",
    "        self.loss = get_object(LOSSES, loss, base_type=BaseLoss, default='mse')\n",
    "        self.losses = [self.loss]\n",
    "        if extra_losses:\n",
    "            self.losses += [get_object(LOSSES, extra_loss, base_type=BaseLoss, default='mse') for extra_loss in extra_losses]\n",
    "    \n",
    "        self.optimizer = get_object(OPTIMIZERS, optimizer, base_type=BaseOptimizer, default='simple')\n",
    "\n",
    "    def _train_iter_forward(self, layer_input, layer_ind: int = 0, end_layer: int = -1):\n",
    "        end_layer = min(end_layer, len(self.layers)) if end_layer >= 0 else len(self.layers)\n",
    "        self._train_inputs[layer_ind] = layer_input\n",
    "\n",
    "        while layer_ind < end_layer:\n",
    "            layer_forward_start_time = time.time()\n",
    "            layer = self.layers[layer_ind]\n",
    "            output = layer(layer_input)\n",
    "            layer_forward_end_time = time.time()\n",
    "    \n",
    "            self._train_outputs.append(output)\n",
    "    \n",
    "            if layer.name not in self.layers_times[\"forward\"]:\n",
    "                self.layers_times[\"forward\"][layer.name] = []\n",
    "            self.layers_times[\"forward\"][layer.name].append(layer_forward_end_time - layer_forward_start_time)\n",
    "\n",
    "            layer_input = output\n",
    "            layer_ind += 1\n",
    "    \n",
    "        return layer_input\n",
    "\n",
    "    def _train_iter_backward(self, doutput, layer_ind: Optional[int] = None, end_layer: int = -1, apply_grads: bool = True):\n",
    "        layer_ind = layer_ind if layer_ind is not None else (len(self.layers) - 1)\n",
    "        end_layer = max(end_layer, -1)\n",
    "        \n",
    "        while layer_ind > end_layer:\n",
    "            layer_backward_start_time = time.time()\n",
    "            layer = self.layers[layer_ind]\n",
    "            output = self._train_outputs[layer_ind]\n",
    "            if layer_ind - 1 > end_layer:\n",
    "                layer_input = self._train_outputs[layer_ind - 1] \n",
    "            else:\n",
    "                layer_input = self._train_inputs[layer_ind]\n",
    "\n",
    "            dinput, updates = layer.backward(layer_input, output, doutput, calc_grads=apply_grads)\n",
    "            # Otimizer apply gradients\n",
    "            if apply_grads:\n",
    "                self.optimizer.add_gradients(layer, updates)\n",
    "            layer_backward_end_time = time.time()\n",
    "            \n",
    "            if layer.name not in self.layers_times[\"backward\"]:\n",
    "                self.layers_times[\"backward\"][layer.name] = []\n",
    "            self.layers_times[\"backward\"][layer.name].append(layer_backward_end_time - layer_backward_start_time)\n",
    "\n",
    "            doutput = dinput\n",
    "            layer_ind -= 1\n",
    "\n",
    "        return doutput\n",
    "\n",
    "    def _calc_losses(self, y, y_pred, val: bool = True):\n",
    "        if val:\n",
    "            all_losses = {l.NAME: l.val_loss(y, y_pred) for l in self.losses}\n",
    "        else:\n",
    "            all_losses = {l.NAME: l.update_epoch(y, y_pred) for l in self.losses}\n",
    "        if len(all_losses) == 1:\n",
    "            return list(all_losses.values())[0]\n",
    "        return all_losses\n",
    "\n",
    "    def train_step(self, X, y):\n",
    "        # Forward pass\n",
    "        y_pred = self._train_iter_forward(X)\n",
    "        # Calc loss and it's derivative\n",
    "        batch_losses = self._calc_losses(y, y_pred, val=False)\n",
    "        dloss = self.loss.derivative(y, y_pred)\n",
    "        # Calc gradients and update weights\n",
    "        self._train_iter_backward(dloss)\n",
    "        self.optimizer.apply_gradients()\n",
    "\n",
    "        return batch_losses\n",
    "\n",
    "    def _start_train(self):\n",
    "        for layer in self.layers:\n",
    "            layer.enable_training()\n",
    "\n",
    "    def _end_train(self):\n",
    "        for layer in self.layers:\n",
    "            layer.disable_training()\n",
    "    \n",
    "    def _clear_batch(self):\n",
    "        self._train_inputs = {}\n",
    "        self._train_outputs = []\n",
    "        for layer in self.layers:\n",
    "            layer.clear_tmp()\n",
    "\n",
    "    def _get_batch(self, batch_idx, X, y=None):\n",
    "        batch_st, batch_end = batch_idx * self.batch_size, (batch_idx + 1) * self.batch_size\n",
    "\n",
    "        if isinstance(X, tuple):\n",
    "            X_batch = (_x[batch_st:batch_end] for _x in X)\n",
    "        else:\n",
    "            X_batch = X[batch_st:batch_end]\n",
    "    \n",
    "        if y is not None:\n",
    "            y_batch = y[batch_st:batch_end]\n",
    "            return X_batch, y_batch\n",
    "    \n",
    "        return X_batch\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, epochs=100, batch_size=32, verbose=1, show_val_loss: bool = True):\n",
    "        self.verbose = verbose or 0\n",
    "        self.batch_size = batch_size\n",
    "        n_samples = len(X)\n",
    "        n_batches = int(np.ceil(n_samples / batch_size))\n",
    "        \n",
    "        self.epoch = (self.epoch or 0) + 1\n",
    "        start_epoch, end_epoch = self.epoch, self.epoch + epochs\n",
    "        \n",
    "        try:\n",
    "            self._start_train()\n",
    "\n",
    "            for epoch in range(start_epoch, end_epoch):\n",
    "                self.epoch = epoch\n",
    "                for loss in self.losses:\n",
    "                    loss.start_epoch()\n",
    "                loss_str = None\n",
    "                \n",
    "                for batch_idx in range(n_batches):\n",
    "                    X_batch, y_batch = self._get_batch(batch_idx, X, y)\n",
    "                    batch_loss = self.train_step(X_batch, y_batch)\n",
    "                    self._clear_batch()\n",
    "    \n",
    "                    if self.verbose <= 0:\n",
    "                        continue\n",
    "                    if isinstance(batch_loss, (int, float)):\n",
    "                        loss_str = f\"Loss: {batch_loss:.4f}\"\n",
    "                    elif isinstance(batch_loss, (list, tuple, set)):\n",
    "                        loss_str = \"Losses: \" + f\", \".join([f\"{cur_loss:.4f}\" for cur_loss in batch_loss])\n",
    "                    elif isinstance(batch_loss, dict):\n",
    "                        loss_str = f\", \".join([f\"{loss_name}: {cur_loss:.4f}\" for loss_name, cur_loss in batch_loss.items()])\n",
    "                    print(f\"\\rBatch {batch_idx + 1}/{n_batches}, {loss_str}\", end=\"\")\n",
    "        \n",
    "                for loss in self.losses:\n",
    "                    loss.end_epoch()\n",
    "    \n",
    "                if show_val_loss and X_val is not None and y_val is not None:\n",
    "                    self._end_train()\n",
    "                    val_loss = self._calc_losses(y_val, self.predict(X_val, batch_size=batch_size))\n",
    "                    self._start_train()\n",
    "                else:\n",
    "                    val_loss = None\n",
    "        \n",
    "                if self.verbose > 0:\n",
    "                    if isinstance(val_loss, (int, float)):\n",
    "                        val_str = f\", Val. Loss: {val_loss:.4f}\"\n",
    "                    elif isinstance(val_loss, (list, tuple, set)):\n",
    "                        val_str = \", Val. Losses: \" + f\", \".join([f\"{cur_loss:.4f}\" for cur_loss in val_loss])\n",
    "                    elif isinstance(val_loss, dict):\n",
    "                        val_str = f\", \".join([f\"Val.{loss_name}: {cur_loss:.4f}\" for loss_name, cur_loss in val_loss.items()])\n",
    "                    else:\n",
    "                        val_str = \"\"\n",
    "                    print(f\"\\rEpoch {self.epoch}/{end_epoch}, {loss_str}{val_str}\")\n",
    "\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    self.plot_epoch(X_val, y_val)\n",
    "\n",
    "            self._end_train()\n",
    "            \n",
    "            if show_val_loss and X_val is not None and y_val is not None:\n",
    "                if len(self.losses) == 1:\n",
    "                    return self.losses[0].history, self.losses[0].val_history\n",
    "                return [(loss.history, loss.val_history) for loss in self.losses]\n",
    "            else:\n",
    "                if len(self.losses) == 1:\n",
    "                    return self.losses[0].history\n",
    "                return [loss.history for loss in self.losses]\n",
    "        except Exception as e:\n",
    "            self._end_train()\n",
    "            raise e\n",
    "\n",
    "    def plot_epoch(self, X_val, y_val):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        n_batches = int(np.ceil(len(X) / batch_size))\n",
    "        output = []\n",
    "        for batch_idx in range(n_batches):\n",
    "            # Forward mini-batch\n",
    "            X_batch = self._get_batch(batch_idx, X)\n",
    "            output.append(self.forward(X_batch))\n",
    "        output = np.concatenate(output, axis=0)\n",
    "        return output\n",
    "\n",
    "    def summary(self, with_name: bool = False):\n",
    "        # Collect info\n",
    "        info = [ # Header\n",
    "            [\"Layer\", \"Input size\", \"Output size\", \"Num params\", \"Activation\"]\n",
    "        ]\n",
    "        if with_name:\n",
    "            info[0].append(\"Unique Name\")\n",
    "    \n",
    "        info_len = list(map(len, info[0]))\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayersBlock):\n",
    "                layer_info = (layer.__class__.__name__, '-', '-', '-', '-')\n",
    "            else:\n",
    "                layer_info = (\n",
    "                    layer.__class__.__name__, \n",
    "                    layer.input_size,\n",
    "                    layer.output_size,\n",
    "                    layer.num_params,\n",
    "                    layer.activation,\n",
    "                )\n",
    "            if with_name:\n",
    "                layer_info += (layer.name,)\n",
    "\n",
    "            layer_info = list(map(str, layer_info))\n",
    "            info.append(layer_info)\n",
    "            \n",
    "            layer_lens = list(map(len, layer_info))\n",
    "            info_len = [max(_prev, _new) for _prev, _new in zip(info_len, layer_lens)]\n",
    "            \n",
    "            if isinstance(layer, LayersBlock):\n",
    "                info.append(layer)\n",
    "    \n",
    "        # Print info\n",
    "        def _print_dash_line():\n",
    "            print(\"+\", end=\"\")\n",
    "            for _len in info_len:\n",
    "                print(\"-\" * (_len + 2), end=\"+\")\n",
    "            print()\n",
    "\n",
    "        def _print_summary(info, with_header=True):\n",
    "            _print_dash_line()\n",
    "            total_params = 0\n",
    "            for row_ind, row_info in enumerate(info):\n",
    "                if isinstance(row_info, LayersBlock):\n",
    "                    block_info = row_info.summary(with_name=with_name, return_array=True)\n",
    "                    total_params += _print_summary(block_info[1:], with_header=False)\n",
    "                else:\n",
    "                    print(\"| \", end=\"\")\n",
    "                    for field, field_len in zip(row_info, info_len):\n",
    "                        print(field.ljust(field_len), end=\" | \") \n",
    "                    print()\n",
    "                    total_params += int(row_info[3]) if row_info[3].isdigit() else 0\n",
    "                if with_header and row_ind == 0:\n",
    "                    _print_dash_line()\n",
    "            _print_dash_line()\n",
    "            return total_params\n",
    "\n",
    "        print(\"Model summary\")\n",
    "        total_params = _print_summary(info)\n",
    "        print(f\"Total trainable params: {total_params:,}\")\n",
    "\n",
    "    def show_time_info(self, with_name: bool = False):\n",
    "        if not self.layers_times[\"forward\"] and self.layers_times[\"backward\"]:\n",
    "            print(\"Model wasn't evaluated yet\")\n",
    "            return\n",
    "\n",
    "        def _print_dash_line(info_len):\n",
    "            print(\"+\", end=\"\")\n",
    "            for _len in info_len:\n",
    "                print(\"-\" * (_len + 2), end=\"+\")\n",
    "            print()\n",
    "        \n",
    "        def _show_time_info(direction: str):\n",
    "            info = [ # Header\n",
    "                [\"Layer\", \"Mesurements\", \"Mean (ms)\", \"Median (ms)\", \"Max (ms)\", \"Min (ms)\"]\n",
    "            ]\n",
    "            if with_name:\n",
    "                info[0].insert(1, \"Unique Name\")\n",
    "            \n",
    "            info_len = list(map(len, info[0]))\n",
    "            \n",
    "            for layer in self.layers:\n",
    "                if layer.name not in self.layers_times[direction]:\n",
    "                    continue\n",
    "                mesurements = np.array(self.layers_times[direction][layer.name])\n",
    "                mesurements *= 1000\n",
    "\n",
    "                layer_info = (layer.__class__.__name__, layer.name) if with_name else (layer.__class__.__name__,)\n",
    "                layer_info += (\n",
    "                    len(mesurements),\n",
    "                    round(np.mean(mesurements), 2),\n",
    "                    round(np.median(mesurements), 2),\n",
    "                    round(np.max(mesurements), 2),\n",
    "                    round(np.min(mesurements), 2)\n",
    "                )\n",
    "                layer_info = list(map(str, layer_info))\n",
    "                info.append(layer_info)\n",
    "                \n",
    "                layer_lens = list(map(len, layer_info))\n",
    "                info_len = [max(_prev, _new) for _prev, _new in zip(info_len, layer_lens)]\n",
    "            print(f\"{direction.title()} stats\")\n",
    "            _print_dash_line(info_len)\n",
    "            for row_ind, row_info in enumerate(info):\n",
    "                print(\"| \", end=\"\")\n",
    "                for field, field_len in zip(row_info, info_len):\n",
    "                    print(field.ljust(field_len), end=\" | \")\n",
    "                print()\n",
    "                if row_ind == 0 or row_ind == len(info) - 1:\n",
    "                    _print_dash_line(info_len)\n",
    "\n",
    "        if self.layers_times[\"forward\"]:\n",
    "            _show_time_info(\"forward\")\n",
    "            print()\n",
    "        if self.layers_times[\"backward\"]:\n",
    "            _show_time_info(\"backward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893bce2-c768-4e42-8485-356ec935464b",
   "metadata": {},
   "source": [
    "### ALIGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb543fdc-53c8-491c-968b-3451099a9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALIGNN(Model):\n",
    "    def __init__(self, block_size=4, input_dim=4, edge_dim=20, output_dims=[32, 64, 128, 128]):\n",
    "        layers = [\n",
    "            ALIGNNBlock(\n",
    "                block_size=block_size, input_dim=input_dim, edge_dim=edge_dim, output_dims=output_dims\n",
    "            ),\n",
    "            GraphAvgPooling(input_size=output_dims[-1]),\n",
    "            Dense(output_dims[-1], 64, activation='silu'),\n",
    "            Dense(64, 1, activation='linear')\n",
    "        ]\n",
    "        super().__init__(layers)\n",
    "\n",
    "    def _get_batch(self, batch_idx, X, y=None):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in range(batch_idx * self.batch_size, (batch_idx + 1) * self.batch_size):\n",
    "            cur_data = X[i]\n",
    "            X_batch.append(\n",
    "                (cur_data.x.numpy(), cur_data.edge_attr.numpy(), cur_data.edge_dist.numpy(), cur_data.edge_index.numpy())\n",
    "            )\n",
    "            if y is not None:\n",
    "                y_batch.append(cur_data.y.numpy())\n",
    "\n",
    "        if y is not None:\n",
    "            y_batch = np.concatenate(y_batch, axis=0)\n",
    "            return X_batch, y_batch\n",
    "        return X_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86acaff5-250d-4dad-ac65-a6a7fd56ad3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### VAE-GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cea2c770-c309-4174-aff6-a88de142a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEGAN(Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        encoder_layers: Optional[List[BaseLayer]] = None,\n",
    "        decoder_layers: Optional[List[BaseLayer]] = None,\n",
    "        discriminator_layers: Optional[List[BaseLayer]] = None,\n",
    "        discriminator_loss_layer_index: Optional[int] = -1,\n",
    "        gamma: float = 1.\n",
    "    ):\n",
    "        all_layers = (encoder_layers or []) + (decoder_layers or []) + (discriminator_layers or [])\n",
    "        super().__init__(all_layers)\n",
    "\n",
    "        self.components = [\"encoder\", \"decoder\", \"discriminator\"]\n",
    "        self.num_layers = {\n",
    "            \"encoder\": len(encoder_layers or []),\n",
    "            \"decoder\": len(decoder_layers or []),\n",
    "            \"discriminator\": len(discriminator_layers or [])\n",
    "        }\n",
    "        self.layers_indexes = {}\n",
    "        self.gamma = gamma\n",
    "        self.discriminator_loss_layer_index = discriminator_loss_layer_index or -1\n",
    "        self._dis_l_ind = None\n",
    "        self._set_indexes()\n",
    "\n",
    "        # Eps for reparameterize\n",
    "        self.eps = None\n",
    "\n",
    "    def _set_indexes(self):\n",
    "        end_ind = 0\n",
    "        for comp in self.components:\n",
    "            st_ind = end_ind\n",
    "            end_ind += self.num_layers[comp]\n",
    "            self.layers_indexes[comp] = {\"start\": st_ind,  \"end\": end_ind}\n",
    "\n",
    "        dis_l_idx = self.discriminator_loss_layer_index\n",
    "        if dis_l_idx < 0:\n",
    "            self._dis_l_ind = max(\n",
    "                self.layers_indexes[\"discriminator\"][\"end\"] + dis_l_idx, \n",
    "                self.layers_indexes[\"discriminator\"][\"start\"] + 1\n",
    "            )\n",
    "        else:\n",
    "            self._dis_l_ind = min(\n",
    "                self.layers_indexes[\"discriminator\"][\"start\"] + dis_l_idx + 1, \n",
    "                self.layers_indexes[\"discriminator\"][\"end\"] - 1\n",
    "            )\n",
    "\n",
    "    def add(self, layer: BaseLayer, component_name: str):\n",
    "        if component_name not in self.components:\n",
    "            raise ValueError(f\"Incorrect component_name = {component_name} (should be on of {self.components})\")\n",
    "\n",
    "        self.layers.insert(self.layers_indexes[component_name][\"end\"], layer)\n",
    "        self.num_layers[component_name] += 1\n",
    "        self._set_indexes()\n",
    "\n",
    "    def compile(self, vae_loss='kl_div', dis_l_loss='mse', gan_loss='softmax_cross_entropy', optimizer='adam'):\n",
    "        self.kl_div_loss = get_object(LOSSES, vae_loss, base_type=BaseLoss, default='kl_div')\n",
    "        self.dis_l_loss = get_object(LOSSES, dis_l_loss, base_type=BaseLoss, default='mse')\n",
    "        self.gan_loss = get_object(LOSSES, gan_loss, base_type=BaseLoss, default='softmax_cross_entropy')\n",
    "\n",
    "        self.losses = [self.kl_div_loss, self.dis_l_loss, self.gan_loss]\n",
    "\n",
    "        self.optimizer = get_object(OPTIMIZERS, optimizer, base_type=BaseOptimizer, default='adam')\n",
    "\n",
    "    def _split_encode(self, out):\n",
    "        mean, logvar = np.split(out, 2, axis=-1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def _reparameterize(self, mean, logvar):\n",
    "        self.eps = np.random.randn(*mean.shape)\n",
    "        return self.eps * np.exp(logvar * .5) + mean\n",
    "\n",
    "    def _reparameterize_derivative(self, dz, mean, logvar):\n",
    "        dmean = np.ones_like(mean)\n",
    "        dlogvar = self.eps * np.exp(logvar * .5) / 2\n",
    "        denc_out = np.concatenate([dz * dmean, dz * dlogvar], axis=1)\n",
    "        return denc_out\n",
    "\n",
    "    def train_step(self, X, *args):\n",
    "        # Helper functions\n",
    "        def get_fwd_indexes(comp_name: str):\n",
    "            return self.layers_indexes[comp_name]['start'], self.layers_indexes[comp_name]['end']\n",
    "\n",
    "        def get_bwd_indexes(comp_name: str):\n",
    "            return self.layers_indexes[comp_name]['end'] - 1, self.layers_indexes[comp_name]['start'] - 1\n",
    "        \n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        # Forward pass VAE\n",
    "        encoded_out = self._train_iter_forward(X, *get_fwd_indexes(\"encoder\"))\n",
    "        mean, logvar = self._split_encode(encoded_out)\n",
    "        z = self._reparameterize(mean, logvar)\n",
    "        z_p = np.random.randn(*z.shape)\n",
    "\n",
    "        both_z = np.concatenate([z, z_p], axis=0)\n",
    "        X_gen = self._train_iter_forward(both_z, *get_fwd_indexes(\"decoder\"))\n",
    "\n",
    "        # Forward pass GAN (concat X and X_gen and permutate)\n",
    "        permutation = np.random.permutation(batch_size * 3)\n",
    "        \n",
    "        combined = np.concatenate([X, X_gen], axis=0)[permutation]\n",
    "        y_true = np.concatenate([np.ones(batch_size), np.zeros(batch_size * 2)], axis=0)[permutation]\n",
    "        # meow meow meow meow meow meow\n",
    "        dis_start_idx, dis_end_idx = get_fwd_indexes(\"discriminator\")\n",
    "        dis_l_out = self._train_iter_forward(combined, dis_start_idx, self._dis_l_ind)\n",
    "        y_logit = self._train_iter_forward(dis_l_out, self._dis_l_ind, dis_end_idx)\n",
    "\n",
    "        # GAN Loss, disciminator backward pass\n",
    "\n",
    "        gan_loss = self.gan_loss.update_epoch(y_true, y_logit)\n",
    "        dgan_loss = self.gan_loss.derivative(y_true, y_logit) # (batch_size * 3)\n",
    "        d_gan_on_dis_l = self._train_iter_backward(dgan_loss, dis_end_idx - 1, self._dis_l_ind - 1)\n",
    "        self._train_iter_backward(d_gan_on_dis_l, self._dis_l_ind - 1, dis_start_idx - 1)\n",
    "\n",
    "        # VAE Losses\n",
    "        inverse_permutation = np.empty_like(permutation)\n",
    "        inverse_permutation[permutation] = np.arange(permutation.size)\n",
    "\n",
    "        dis_l_out = dis_l_out[inverse_permutation]\n",
    "        dis_l_out_real, dis_l_out_fake = dis_l_out[:batch_size], dis_l_out[batch_size:batch_size*2]\n",
    "\n",
    "        dis_l_loss = self.dis_l_loss.update_epoch(dis_l_out_real, dis_l_out_fake)\n",
    "        d_dis_l_loss = self.dis_l_loss.derivative(dis_l_out_real, dis_l_out_fake) # (batch_size)\n",
    "\n",
    "        # Calc decoder (generator) loss\n",
    "        decoder_loss = self.gamma * dis_l_loss - gan_loss\n",
    "        d_decoder_loss = self.gamma * d_dis_l_loss - d_gan_on_dis_l[inverse_permutation][batch_size:batch_size*2]\n",
    "        \n",
    "        # 0 to grads we don't need, need only for X_gen from z\n",
    "        d_decoder_loss = np.concatenate([np.zeros_like(d_decoder_loss), d_decoder_loss, np.zeros_like(d_decoder_loss)], axis=0)\n",
    "        # Permutate on correct positions\n",
    "        d_decoder_loss = d_decoder_loss[permutation]\n",
    "        \n",
    "        # backward through dis without weights changing\n",
    "        d_X_gen = self._train_iter_backward(d_decoder_loss, self._dis_l_ind - 1, dis_start_idx - 1, apply_grads = False)\n",
    "        # inverse permutate ant take only grads we need (for X_gen)\n",
    "        d_X_gen = d_X_gen[inverse_permutation][batch_size:]\n",
    "\n",
    "        self._train_iter_backward(d_X_gen, *get_bwd_indexes(\"decoder\"))\n",
    "\n",
    "        # Calc encoder loss \n",
    "\n",
    "        # Calc grads only by dis_l_loss\n",
    "        d_dis_l_loss = np.concatenate([np.zeros_like(d_dis_l_loss), d_dis_l_loss, np.zeros_like(d_dis_l_loss)], axis=0)\n",
    "        d_dis_l_loss = d_dis_l_loss[permutation]\n",
    "        d_X_gen = self._train_iter_backward(d_dis_l_loss, self._dis_l_ind - 1, dis_start_idx - 1, apply_grads = False)\n",
    "        d_X_gen = d_X_gen[inverse_permutation][batch_size:]\n",
    "        d_z = self._train_iter_backward(d_X_gen, *get_bwd_indexes(\"decoder\"), apply_grads = False)\n",
    "        # Take only for z from X\n",
    "        d_z = d_z[:batch_size]\n",
    "        denc_out = self._reparameterize_derivative(d_z, mean, logvar)\n",
    "\n",
    "        kl_div_loss = self.kl_div_loss.update_epoch(mean, logvar)\n",
    "        encoder_loss = dis_l_loss + kl_div_loss\n",
    "\n",
    "        d_encoder_loss = denc_out + self.kl_div_loss.derivative(mean, logvar)\n",
    "        self._train_iter_backward(d_encoder_loss, *get_bwd_indexes(\"encoder\"))\n",
    "        self.optimizer.apply_gradients()\n",
    "        \n",
    "        return {\n",
    "            \"GAN Loss\": gan_loss,\n",
    "            \"Dis_l Loss\": dis_l_loss,\n",
    "            \"Decoder Loss\": decoder_loss,\n",
    "            \"KL Div.\": kl_div_loss,\n",
    "            \"Encoder Loss\": encoder_loss\n",
    "        }\n",
    "\n",
    "    def forward_component(self, X, component: str, batch_size: int = 64, *args, **kwargs):\n",
    "        if component not in self.layers_indexes:\n",
    "            raise ValueError(f\"Incorrect component name, should be one of {list(self.layers_indexes)}\")\n",
    "        layer_start, layer_end = self.layers_indexes[component][\"start\"], self.layers_indexes[component][\"end\"]\n",
    "        n_batches = int(np.ceil(X.shape[0] / batch_size))\n",
    "        output = []\n",
    "        for batch in range(n_batches):\n",
    "            # Forward mini-batch\n",
    "            batch_st, batch_end = batch * batch_size, (batch + 1) * batch_size\n",
    "            out = X[batch_st:batch_end]\n",
    "            for layer_idx in range(layer_start, layer_end):\n",
    "                out = self.layers[layer_idx](out)\n",
    "            output.append(out)\n",
    "        output = np.concatenate(output, axis=0)            \n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def encode(self, X, batch_size: int = 64, reparameterize: bool = True):\n",
    "        output = self.forward_component(X, component=\"encoder\", batch_size=batch_size)\n",
    "        mean, logvar = self._split_encode(output)\n",
    "        if reparameterize:\n",
    "            return self._reparameterize(mean, logvar)\n",
    "        return mean, logvar\n",
    "\n",
    "    def decode(self, X, batch_size: int = 64):\n",
    "        output = self.forward_component(X, component=\"decoder\", batch_size=batch_size)\n",
    "        return output\n",
    "\n",
    "    def discriminate(self, X, batch_size: int = 64):\n",
    "        output = self.forward_component(X, component=\"discriminator\", batch_size=batch_size)\n",
    "        return output\n",
    "\n",
    "    def plot_epoch(self, X_val, y_val):\n",
    "        # Plot latent 3d\n",
    "        z = self.encode(X_val)\n",
    "        \n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in range(10):\n",
    "            ind = np.where(y_val == i)\n",
    "            ax.scatter(z[ind][:, 0], z[ind][:, 1], z[ind][:, 2], s=0.5, label=str(i))\n",
    "        lgnd = ax.legend()\n",
    "        for i in range(10):\n",
    "            lgnd.legend_handles[i]._sizes = [30]\n",
    "    \n",
    "        plt.savefig(f\"latent_space_epoch_{self.epoch:04d}.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # Images samples\n",
    "        if self.epoch == 1:\n",
    "            fig = plt.figure(figsize=(4, 4))\n",
    "            for i in range(16):\n",
    "                plt.subplot(4, 4, i + 1)\n",
    "                plt.imshow(X_val[i, 0, :, :], cmap='gray')\n",
    "                plt.title(f\"Orig: {y_val[i]}\")\n",
    "                plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'orig_images.png')\n",
    "            plt.show()\n",
    "        \n",
    "        recon = self.decode(z[:16])\n",
    "        dis_labels = self.discriminate(recon)\n",
    "        dis_labels = np.where(np.argmax(dis_labels, axis=1) == 1, \"Real\", \"Fake\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        for i in range(recon.shape[0]):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(recon[i, 0, :, :], cmap='gray')\n",
    "            plt.title(f\"Disc: {dis_labels[i]}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'image_at_epoch_{self.epoch:04d}.png')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19efba62-98f0-4b18-8c76-4f8362d65fec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29fff4da-aaa8-4a0a-85fe-85c7f2dac038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import inspect\n",
    "\n",
    "def _get_layers_info(layers):\n",
    "    weights_map = {}\n",
    "    layers_meta_info = {}\n",
    "    for i, layer in enumerate(layers):\n",
    "        del_atrrs = [\"name\", \"input_size\", \"output_size\", \"activation\"]\n",
    "        \n",
    "        if isinstance(layer, LayersBlock):\n",
    "            block_weights, block_layers_meta_info = _get_layers_info(layer.layers)\n",
    "            weights_map.update(block_weights)\n",
    "            del_atrrs += ['layers']\n",
    "        else:\n",
    "            block_layers_meta_info = None\n",
    "    \n",
    "        attr = inspect.getmembers(layer, lambda a:not(inspect.isroutine(a)))\n",
    "        attr = dict([\n",
    "            a for a in attr \n",
    "            if (\n",
    "                (a[1] is not None)\n",
    "                and not a[0].startswith('_')\n",
    "                and a[0] not in del_atrrs\n",
    "            )\n",
    "        ])\n",
    "        attr_names = list(attr)\n",
    "        for w_name in attr_names:\n",
    "            if isinstance(attr[w_name], np.ndarray):\n",
    "                weights_map[\"_\".join([layer.name, w_name])] = attr[w_name]\n",
    "                attr.pop(w_name)\n",
    "            elif isinstance(attr[w_name], Activation):\n",
    "                attr[w_name] = attr[w_name].NAME\n",
    "    \n",
    "        layers_meta_info[layer.name] = {\n",
    "            \"index\": i,\n",
    "            \"class_name\": layer.__class__.__name__,\n",
    "            \"input_size\": layer.input_size if hasattr(layer, 'input_size') else None, \n",
    "            \"output_size\": layer.output_size if hasattr(layer, 'output_size') else None,\n",
    "            \"activation\": layer.activation.NAME if hasattr(layer, 'activation') else None,\n",
    "            \"other\": attr,\n",
    "        }\n",
    "        if block_layers_meta_info:\n",
    "            layers_meta_info[layer.name][\"block_layers\"] = block_layers_meta_info\n",
    "\n",
    "    return weights_map, layers_meta_info\n",
    "\n",
    "\n",
    "def save_model(model, dir_name: str):\n",
    "    weights_map, layers_meta_info = _get_layers_info(model.layers)\n",
    "    meta_info = {\n",
    "        \"layers\": layers_meta_info\n",
    "    }\n",
    "    \n",
    "    if hasattr(model, \"losses\"):\n",
    "        meta_info[\"losses\"] = [l.NAME for l in model.losses]\n",
    "    if hasattr(model, \"optimizer\"):\n",
    "        meta_info[\"optimizer\"] = model.optimizer.NAME\n",
    "    \n",
    "    if not os.path.exists(dir_name) or not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "    try:\n",
    "        np.savez(os.path.join(dir_name, \"weights.npz\"), **weights_map)\n",
    "        with open(os.path.join(dir_name, \"metainfo.json\"), \"w\") as f:\n",
    "            json.dump(meta_info, f, skipkeys=True, ensure_ascii=False)\n",
    "        print(f\"Dumped model to {dir_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to dump model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72018fdc-ad5c-47ac-92e5-c6544162ff27",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ceed6e9-ea07-4cbd-994a-799f7b84dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(train_history, val_history=None, xticks=None):\n",
    "    if isinstance(train_history, (list, np.ndarray)):\n",
    "        if not isinstance(train_history[0], (list, np.ndarray)):\n",
    "            train_history = {\"Train\": train_history}\n",
    "        else:\n",
    "            train_history = {f\"Train_{i}\": hist for i, hist in enumerate(train_history)}\n",
    "    if val_history is not None and isinstance(val_history, (list, np.ndarray)):\n",
    "        if not isinstance(val_history[0], (list, np.ndarray)):\n",
    "            val_history = {\"Validation\": val_history}\n",
    "        else:\n",
    "            val_history = {f\"Validation_{i}\": hist for i, hist in enumerate(val_history)}\n",
    "    elif val_history is None:\n",
    "        val_history = {f\"Validation_{i}\": None for i in range(len(train_history))}\n",
    "\n",
    "    assert len(train_history) == len(val_history), \"Val history should match train history\"\n",
    "\n",
    "    cols = int(np.sqrt(len(train_history)))\n",
    "    rows = int(np.ceil(len(train_history) / cols))\n",
    "\n",
    "    plt.figure(figsize=(8 * cols, 6 * rows))\n",
    "    subpl_i = 1\n",
    "    for (tr_label, tr_hist), (val_label, val_hist) in zip(train_history.items(), val_history.items()):\n",
    "        plt.subplot(rows, cols, subpl_i)\n",
    "\n",
    "        plt.plot(tr_hist, c='b', label=tr_label)\n",
    "        if val_hist is not None:\n",
    "            plt.plot(val_hist, c='r', label=val_label)\n",
    "        \n",
    "        plt.legend()\n",
    "        if xticks is not None:\n",
    "            plt.xticks(xticks)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        subpl_i += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56826179-dbfe-4b56-acea-07383e50a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, numpy: bool = False):\n",
    "    classes = np.unique(y_true)\n",
    "\n",
    "    results = [\n",
    "        [\n",
    "            np.sum((y_pred == i) & (y_true == j))\n",
    "            for j in classes\n",
    "        ]\n",
    "        for i in classes\n",
    "    ]\n",
    "    if numpy:\n",
    "        return np.array(results)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        results, \n",
    "        columns=pd.MultiIndex.from_tuples(\n",
    "            [(\"Actual\", str(i)) for i in classes]\n",
    "        ),\n",
    "        index=pd.MultiIndex.from_tuples(\n",
    "            [(\"Predict\", str(i)) for i in classes]\n",
    "        )\n",
    "    )\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, numpy=True)\n",
    "    total = np.sum(conf_matrix, axis=1)\n",
    "    return np.diagonal(conf_matrix) / total\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, numpy=True)\n",
    "    total = np.sum(conf_matrix, axis=0)\n",
    "    return np.diagonal(conf_matrix) / total\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc5dc068-0072-4848-820c-1605d92b3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "\n",
    "def auc(fpr, tpr):\n",
    "    area = trapezoid(tpr, fpr)\n",
    "    return float(area)\n",
    "\n",
    "def roc_curve(y_true, y_score):\n",
    "    y_true = y_true == 1\n",
    "\n",
    "    # sort scores and corresponding truth values\n",
    "    desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1]\n",
    "    y_score = y_score[desc_score_indices]\n",
    "    y_true = y_true[desc_score_indices]\n",
    "\n",
    "    distinct_value_indices = np.where(np.diff(y_score))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n",
    "\n",
    "    # accumulate the true positives with decreasing threshold\n",
    "    tps = np.cumsum(y_true, dtype=np.float64)[threshold_idxs]\n",
    "    fps = 1 + threshold_idxs - tps\n",
    "    \n",
    "    fpr = fps / fps[-1]\n",
    "    tpr = tps / tps[-1]\n",
    "    return auc(fpr, tpr), fpr, tpr\n",
    "\n",
    "def roc_curve_multiclass(y_true, y_score):\n",
    "    results = {}\n",
    "    for cls in sorted(np.unique(y_true)):\n",
    "        bin_y_true = (y_true == cls).astype(int)\n",
    "        bin_y_score = y_score[:, cls]\n",
    "        auc, fpr, tpr = roc_curve(bin_y_true, bin_y_score)\n",
    "        results[cls] = (auc, fpr, tpr)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3b2e1c4-be34-49e6-96a7-31985098d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_classes(y_pred):\n",
    "    softmax = StableSoftmax()\n",
    "    return np.argmax(softmax(y_pred), axis=1)\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def show_metrics(y_true, y_pred):\n",
    "    accuracy, precision, recall, f1 = get_metrics(y_true, y_pred)\n",
    "    print(\"Metrics by classes\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: \" + \"; \".join([f'{p:.4f}' for p in precision]))\n",
    "    print(f\"Recall: \" + \"; \".join([f'{r:.4f}' for r in recall]))\n",
    "    print(f\"F1-Score: \" + \"; \".join([f'{f:.4f}' for f in f1]))\n",
    "\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = get_predict_classes(y_pred)\n",
    "    return show_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372dd8b-79e3-4dc2-be1d-198fda532119",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca337601-a191-4870-9254-ceab8f6ec518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b0d4718-25cd-4388-8238-7e12ac633f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary\n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| Layer           | Input size | Output size | Num params | Activation | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| ALIGNNBlock     | -          | -           | -          | -          | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| EdgeGatedGraphConv | -          | -           | -          | -          | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| Dense           | 29         | 32          | 960        | silu       | \n",
      "| Dense           | 32         | 32          | 1056       | linear     | \n",
      "| Dense           | 32         | 1           | 33         | sigmoid    | \n",
      "| Dense           | 36         | 32          | 1184       | silu       | \n",
      "| Dense           | 32         | 32          | 1056       | linear     | \n",
      "| Dense           | 52         | 32          | 1696       | silu       | \n",
      "| Dense           | 32         | 32          | 1056       | linear     | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| EdgeGatedGraphConv | -          | -           | -          | -          | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| Dense           | 97         | 64          | 6272       | silu       | \n",
      "| Dense           | 64         | 64          | 4160       | linear     | \n",
      "| Dense           | 64         | 1           | 65         | sigmoid    | \n",
      "| Dense           | 96         | 64          | 6208       | silu       | \n",
      "| Dense           | 64         | 64          | 4160       | linear     | \n",
      "| Dense           | 96         | 64          | 6208       | silu       | \n",
      "| Dense           | 64         | 64          | 4160       | linear     | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| EdgeGatedGraphConv | -          | -           | -          | -          | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| Dense           | 193        | 128         | 24832      | silu       | \n",
      "| Dense           | 128        | 128         | 16512      | linear     | \n",
      "| Dense           | 128        | 1           | 129        | sigmoid    | \n",
      "| Dense           | 192        | 128         | 24704      | silu       | \n",
      "| Dense           | 128        | 128         | 16512      | linear     | \n",
      "| Dense           | 192        | 128         | 24704      | silu       | \n",
      "| Dense           | 128        | 128         | 16512      | linear     | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| EdgeGatedGraphConv | -          | -           | -          | -          | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| Dense           | 385        | 128         | 49408      | silu       | \n",
      "| Dense           | 128        | 128         | 16512      | linear     | \n",
      "| Dense           | 128        | 1           | 129        | sigmoid    | \n",
      "| Dense           | 256        | 128         | 32896      | silu       | \n",
      "| Dense           | 128        | 128         | 16512      | linear     | \n",
      "| Dense           | 256        | 128         | 32896      | silu       | \n",
      "| Dense           | 128        | 128         | 16512      | linear     | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "| GraphAvgPooling | 128        | 128         | 0          | linear     | \n",
      "| Dense           | 128        | 64          | 8256       | silu       | \n",
      "| Dense           | 64         | 1           | 65         | linear     | \n",
      "+-----------------+------------+-------------+------------+------------+\n",
      "Total trainable params: 335,365\n"
     ]
    }
   ],
   "source": [
    "# Create model with all hidden layers\n",
    "model = ALIGNN(block_size=4)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6f35f68d-68e7-4dc7-8f8d-1bcb02b9f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=AdamOptimizer(learning_rate=LEARNING_RATE),\n",
    "    loss='mse',\n",
    "    extra_losses=['mae', 'ewt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65d560db-f17f-4a50-a34c-a5e274c15974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, mse: 0.2885, mae: 0.4717, ewt: 0.0029Val.mse: 0.2210, Val.mae: 0.4274, Val.ewt: 0.0000\n",
      "Epoch 2/21, mse: 0.2687, mae: 0.4647, ewt: 0.0005Val.mse: 0.2206, Val.mae: 0.4258, Val.ewt: 0.0000\n",
      "Epoch 3/21, mse: 0.2670, mae: 0.4647, ewt: 0.0005Val.mse: 0.2217, Val.mae: 0.4245, Val.ewt: 0.0000\n",
      "Epoch 4/21, mse: 0.2662, mae: 0.4647, ewt: 0.0010Val.mse: 0.2222, Val.mae: 0.4242, Val.ewt: 0.0000\n",
      "Epoch 5/21, mse: 0.2659, mae: 0.4646, ewt: 0.0010Val.mse: 0.2225, Val.mae: 0.4240, Val.ewt: 0.0000\n",
      "Batch 103/2077, mse: 0.2624, mae: 0.4666, ewt: 0.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_history, val_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[80], line 149\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, X, y, X_val, y_val, epochs, batch_size, verbose, show_val_loss)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[1;32m    148\u001b[0m     X_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batch(batch_idx, X, y)\n\u001b[0;32m--> 149\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_batch()\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[80], line 91\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_iter_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# Calc loss and it's derivative\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     batch_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_losses(y, y_pred, val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[80], line 38\u001b[0m, in \u001b[0;36mModel._train_iter_forward\u001b[0;34m(self, layer_input, layer_ind, end_layer)\u001b[0m\n\u001b[1;32m     36\u001b[0m layer_forward_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     37\u001b[0m layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[layer_ind]\n\u001b[0;32m---> 38\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m layer_forward_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "Cell \u001b[0;32mIn[50], line 66\u001b[0m, in \u001b[0;36mLayersBlock.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 66\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_tmp()\n",
      "Cell \u001b[0;32mIn[52], line 59\u001b[0m, in \u001b[0;36mALIGNNBlock.forward\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Pass through each GCN layer\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_names):\n\u001b[0;32m---> 59\u001b[0m     node_feats, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node_feats\n",
      "Cell \u001b[0;32mIn[50], line 45\u001b[0m, in \u001b[0;36mLayersBlock._forward_layer\u001b[0;34m(self, layer_name, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers_inputs\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[1;32m     44\u001b[0m layer_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_names\u001b[38;5;241m.\u001b[39mindex(layer_name)\n\u001b[0;32m---> 45\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[51], line 69\u001b[0m, in \u001b[0;36mEdgeGatedGraphConv.forward\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m message_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X_src, X_dst, edge_attr, edge_dist[:, np\u001b[38;5;241m.\u001b[39mnewaxis]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Forward message MLP\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage_in\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage_out\u001b[39m\u001b[38;5;124m'\u001b[39m, messages)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Get gate activation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 45\u001b[0m, in \u001b[0;36mLayersBlock._forward_layer\u001b[0;34m(self, layer_name, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers_inputs\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[1;32m     44\u001b[0m layer_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_names\u001b[38;5;241m.\u001b[39mindex(layer_name)\n\u001b[0;32m---> 45\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36mDense.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 17\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[1;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(output)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history, val_history = model.fit(\n",
    "    train_dataset, 0, \n",
    "    val_dataset, y_val,\n",
    "    epochs=20,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0f2975a-a9fc-4f21-aa03-4e4f993e5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4bf5258-cec6-41a0-b889-93a9d0f88186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/28, mse: 217.3108, mae: 0.9530, ewt: 0.0193Val.mse: 0.2207, Val.mae: 0.4271, Val.ewt: 0.0000\n",
      "Epoch 9/28, mse: 0.2654, mae: 0.4645, ewt: 0.0000Val.mse: 0.2225, Val.mae: 0.4239, Val.ewt: 0.0000\n",
      "Epoch 10/28, mse: 0.2652, mae: 0.4643, ewt: 0.0000Val.mse: 0.2230, Val.mae: 0.4237, Val.ewt: 0.0000\n",
      "Epoch 11/28, mse: 0.2694, mae: 0.4646, ewt: 0.0000Val.mse: 0.2230, Val.mae: 0.4236, Val.ewt: 0.0000\n",
      "Epoch 12/28, mse: 0.2682, mae: 0.4648, ewt: 0.0014Val.mse: 0.2231, Val.mae: 0.4236, Val.ewt: 0.0000\n",
      "Epoch 13/28, mse: 0.2659, mae: 0.4647, ewt: 0.0010Val.mse: 0.2230, Val.mae: 0.4237, Val.ewt: 0.0000\n",
      "Epoch 14/28, mse: 0.2662, mae: 0.4650, ewt: 0.0005Val.mse: 0.2229, Val.mae: 0.4237, Val.ewt: 0.0000\n",
      "Epoch 15/28, mse: 0.2665, mae: 0.4650, ewt: 0.0000Val.mse: 0.2224, Val.mae: 0.4240, Val.ewt: 0.0000\n",
      "Epoch 16/28, mse: 10.0407, mae: 0.6096, ewt: 0.0010Val.mse: 0.2222, Val.mae: 0.4282, Val.ewt: 0.0000\n",
      "Epoch 17/28, mse: 0.2429, mae: 0.4258, ewt: 0.0087Val.mse: 0.2321, Val.mae: 0.4265, Val.ewt: 0.0066\n",
      "Epoch 18/28, mse: 0.1386, mae: 0.2843, ewt: 0.0477Val.mse: 0.4237, Val.mae: 0.5108, Val.ewt: 0.0229\n",
      "Epoch 19/28, mse: 0.0832, mae: 0.2081, ewt: 0.0780Val.mse: 0.3789, Val.mae: 0.4750, Val.ewt: 0.0975\n",
      "Epoch 20/28, mse: 0.0790, mae: 0.1977, ewt: 0.0818Val.mse: 0.4257, Val.mae: 0.5094, Val.ewt: 0.0591\n",
      "Epoch 21/28, mse: 0.0827, mae: 0.1989, ewt: 0.1045Val.mse: 0.3466, Val.mae: 0.4777, Val.ewt: 0.0098\n",
      "Epoch 22/28, mse: 0.1673, mae: 0.2849, ewt: 0.0717Val.mse: 0.4190, Val.mae: 0.5158, Val.ewt: 0.0072\n",
      "Epoch 23/28, mse: 0.0979, mae: 0.2109, ewt: 0.0953Val.mse: 0.3857, Val.mae: 0.4786, Val.ewt: 0.0947\n",
      "Epoch 24/28, mse: 0.0675, mae: 0.1734, ewt: 0.1271Val.mse: 0.4004, Val.mae: 0.4873, Val.ewt: 0.0643\n",
      "Epoch 25/28, mse: 0.0677, mae: 0.1751, ewt: 0.1180Val.mse: 0.3956, Val.mae: 0.4875, Val.ewt: 0.0977\n",
      "Epoch 26/28, mse: 0.0647, mae: 0.1698, ewt: 0.1290Val.mse: 0.3969, Val.mae: 0.4868, Val.ewt: 0.0868\n",
      "Epoch 27/28, mse: 0.1938, mae: 0.2957, ewt: 0.0785Val.mse: 0.2211, Val.mae: 0.4250, Val.ewt: 0.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_history, val_history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     train_dataset, \u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m      3\u001b[0m     val_dataset, y_val,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_history, val_history = model.fit(\n",
    "    train_dataset, 0, \n",
    "    val_dataset, y_val,\n",
    "    epochs=20,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35fe29bb-cc28-4698-b31a-70d8d91c3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped model to transformer_18_11/\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"alignn_18_11/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c85bfed5-720d-414c-8455-1a673173657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward stats\n",
      "+----------------------+-------------+-----------+-------------+----------+----------+\n",
      "| Layer                | Mesurements | Mean (ms) | Median (ms) | Max (ms) | Min (ms) | \n",
      "+----------------------+-------------+-----------+-------------+----------+----------+\n",
      "| PositionalEncoding   | 6080        | 1.34      | 1.22        | 20.23    | 0.22     | \n",
      "| TransformerBlock     | 6080        | 563.1     | 560.2       | 865.84   | 530.27   | \n",
      "| TransformerBlock     | 6080        | 555.01    | 552.18      | 841.11   | 516.56   | \n",
      "| TransformerBlock     | 6080        | 556.11    | 553.2       | 890.51   | 514.35   | \n",
      "| GlobalAveragePooling | 6080        | 0.17      | 0.17        | 1.2      | 0.15     | \n",
      "| Dense                | 6080        | 0.32      | 0.14        | 12.33    | 0.12     | \n",
      "| Dense                | 6080        | 0.06      | 0.04        | 2.98     | 0.04     | \n",
      "| Dense                | 6080        | 0.01      | 0.01        | 0.1      | 0.0      | \n",
      "+----------------------+-------------+-----------+-------------+----------+----------+\n",
      "\n",
      "Backward stats\n",
      "+----------------------+-------------+-----------+-------------+----------+----------+\n",
      "| Layer                | Mesurements | Mean (ms) | Median (ms) | Max (ms) | Min (ms) | \n",
      "+----------------------+-------------+-----------+-------------+----------+----------+\n",
      "| PositionalEncoding   | 6080        | 0.0       | 0.0         | 0.22     | 0.0      | \n",
      "| TransformerBlock     | 6080        | 128.07    | 125.81      | 256.48   | 122.15   | \n",
      "| TransformerBlock     | 6080        | 125.86    | 123.74      | 292.22   | 108.5    | \n",
      "| TransformerBlock     | 6080        | 129.79    | 127.95      | 214.76   | 122.68   | \n",
      "| GlobalAveragePooling | 6080        | 0.13      | 0.12        | 0.62     | 0.12     | \n",
      "| Dense                | 6080        | 0.24      | 0.04        | 18.73    | 0.04     | \n",
      "| Dense                | 6080        | 0.04      | 0.04        | 1.56     | 0.03     | \n",
      "| Dense                | 6080        | 0.01      | 0.01        | 0.17     | 0.01     | \n",
      "+----------------------+-------------+-----------+-------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "model.show_time_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f18d8-043e-4e11-bab8-63363132c1fa",
   "metadata": {},
   "source": [
    "# Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30399ecc-21ae-4396-ac2f-042fd0b9b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.loss.history\n",
    "val_history = model.loss.val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee25b3d2-bcf8-42c6-8880-7b66560b5520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e064faa7-e01e-4101-98f9-dac6af9f27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_raw = model.predict(X_test)\n",
    "\n",
    "softmax = StableSoftmax()\n",
    "y_pred_proba = softmax(y_pred_raw)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2431fe18-5c65-4111-91bb-56d565eb90d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics by classes\n",
      "Accuracy: 0.8615\n",
      "Precision: 0.8760; 0.8276\n",
      "Recall: 0.9224; 0.7405\n",
      "F1-Score: 0.8986; 0.7816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Predict</th>\n",
       "      <th>0</th>\n",
       "      <td>2211</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Actual     \n",
       "               0    1\n",
       "Predict 0   2211  313\n",
       "        1    186  893"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eval model on test\n",
    "show_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de44665c-8174-434c-923e-4216f00508dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc, fpr, tpr = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67053c-03df-497e-883f-9d2b03249065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
